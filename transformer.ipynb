{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56c031b5",
   "metadata": {},
   "source": [
    "# Text Classification Using Transformer Networks (BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40bd59e",
   "metadata": {},
   "source": [
    "Some initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "133ffdc9-f28b-46fa-84ee-19ded042aaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting filelock (from datasets)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.2.1)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets) (3.9.3)\n",
      "Collecting huggingface-hub>=0.23.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.26.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.26.3-py3-none-any.whl (447 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m447.6/447.6 kB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, tqdm, requests, multiprocess, filelock, huggingface-hub, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.2\n",
      "    Uninstalling tqdm-4.66.2:\n",
      "      Successfully uninstalled tqdm-4.66.2\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "Successfully installed datasets-3.1.0 filelock-3.16.1 huggingface-hub-0.26.3 multiprocess-0.70.16 requests-2.32.3 tqdm-4.67.1 xxhash-3.5.0\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m435.0/435.0 kB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m117.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, regex, tokenizers, transformers\n",
      "Successfully installed regex-2024.11.6 safetensors-0.4.5 tokenizers-0.20.3 transformers-4.46.3\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.1.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (0.26.3)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from accelerate) (0.4.5)\n",
      "Collecting torch>=1.10.0 (from accelerate)\n",
      "  Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch>=1.10.0->accelerate)\n",
      "  Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=1.10.0->accelerate)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
      "Downloading accelerate-1.1.1-py3-none-any.whl (333 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m333.2/333.2 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, accelerate\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12\n",
      "    Uninstalling sympy-1.12:\n",
      "      Successfully uninstalled sympy-1.12\n",
      "Successfully installed accelerate-1.1.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.1 triton-3.1.0\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install datasets\n",
    "!pip3 install transformers\n",
    "!pip install -U accelerate\n",
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3afe3bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "random seed: 1234\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# enable tqdm in pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# set to True to use the gpu (if there is one available)\n",
    "use_gpu = True\n",
    "\n",
    "# select device\n",
    "device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')\n",
    "print(f'device: {device.type}')\n",
    "\n",
    "# random seed\n",
    "seed = 1234\n",
    "\n",
    "# set random seed\n",
    "if seed is not None:\n",
    "    print(f'random seed: {seed}')\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3441f3",
   "metadata": {},
   "source": [
    "Read the train/dev/test datasets and create a HuggingFace `Dataset` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1885c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dota_data(filename):\n",
    "    # read csv file\n",
    "    df = pd.read_csv(filename, header=0)\n",
    "    # Get only the text and label columns\n",
    "    return df[[\"text\",\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d03f51a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COMMEND ME TY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sorry nex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is the best soup?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>man that silence on axe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not coming into play</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>wt?f?asfU JGOFIDLK,YH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>you must really suck</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>YOU HAVE IDIOT PLAYER</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>SUPER IDIOT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>fuck off weab</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3267 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         text  label\n",
       "0               COMMEND ME TY      0\n",
       "1                   sorry nex      0\n",
       "2      what is the best soup?      0\n",
       "3     man that silence on axe      0\n",
       "4        not coming into play      0\n",
       "...                       ...    ...\n",
       "3262    wt?f?asfU JGOFIDLK,YH      1\n",
       "3263     you must really suck      2\n",
       "3264    YOU HAVE IDIOT PLAYER      2\n",
       "3265              SUPER IDIOT      2\n",
       "3266            fuck off weab      2\n",
       "\n",
       "[3267 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = open('classes.txt').read().splitlines()\n",
    "data = read_dota_data('1/tagged-data.csv')\n",
    "print(labels)\n",
    "data = data.rename(columns={\"target\": \"label\"})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e7518aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rows: 2,613\n",
      "eval rows: 327\n",
      "test rows: 327\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, eval_and_test_df = train_test_split(data, train_size=0.8)\n",
    "eval_df, test_df = train_test_split(eval_and_test_df, train_size=0.5)\n",
    "train_df.reset_index(inplace=True, drop=True)\n",
    "eval_df.reset_index(inplace=True, drop=True)\n",
    "test_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(f'train rows: {len(train_df.index):,}')\n",
    "print(f'eval rows: {len(eval_df.index):,}')\n",
    "print(f'test rows: {len(test_df.index):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0b3c727f-1bef-45b8-a179-f4b3bcd974c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>btch</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>him go to school</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>best carry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comend tusk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can we end PLS BRO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>this pudge so fucking stupid</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>second try lucky</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>u know that</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>it took my shaman 12 min to ward my lane</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>why meepo so noob</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>327 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         text  label\n",
       "0                                        btch      2\n",
       "1                            him go to school      0\n",
       "2                                  best carry      0\n",
       "3                                 comend tusk      0\n",
       "4                          can we end PLS BRO      0\n",
       "..                                        ...    ...\n",
       "322              this pudge so fucking stupid      2\n",
       "323                          second try lucky      0\n",
       "324                               u know that      0\n",
       "325  it took my shaman 12 min to ward my lane      0\n",
       "326                         why meepo so noob      2\n",
       "\n",
       "[327 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e06f040b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2613\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 327\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 327\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "ds = DatasetDict()\n",
    "ds['train'] = Dataset.from_pandas(train_df)\n",
    "ds['validation'] = Dataset.from_pandas(eval_df)\n",
    "ds['test'] = Dataset.from_pandas(test_df)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac23185a",
   "metadata": {},
   "source": [
    "Tokenize the texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "65e8d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "transformer_name = 'bert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(transformer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "52a2caf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516d2d24ecdf4bb8b3f0effb77659253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2613 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa16ac738aa4fff90520c8d384a6d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/327 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 1128, 1132, 1198, 1112, 6870, 1183, 1112...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 4877, 2286, 185, 3447, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 1831, 28000, 1158, 1105, 1505, 175, 4419...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 142, 16769, 7462, 22983, 2036, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 1842, 1183, 136, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 192, 1204, 2087, 1110, 1142, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 7642, 5773, 102]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 2959, 3713, 102]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 1160, 12261, 188, 18628, 4206, 23684, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>2</td>\n",
       "      <td>[101, 1327, 170, 14908, 7051, 1591, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2613 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                          input_ids  \\\n",
       "0         0  [101, 1128, 1132, 1198, 1112, 6870, 1183, 1112...   \n",
       "1         0                  [101, 4877, 2286, 185, 3447, 102]   \n",
       "2         1  [101, 1831, 28000, 1158, 1105, 1505, 175, 4419...   \n",
       "3         0          [101, 142, 16769, 7462, 22983, 2036, 102]   \n",
       "4         0                        [101, 1842, 1183, 136, 102]   \n",
       "...     ...                                                ...   \n",
       "2608      0            [101, 192, 1204, 2087, 1110, 1142, 102]   \n",
       "2609      0                             [101, 7642, 5773, 102]   \n",
       "2610      0                             [101, 2959, 3713, 102]   \n",
       "2611      0   [101, 1160, 12261, 188, 18628, 4206, 23684, 102]   \n",
       "2612      2           [101, 1327, 170, 14908, 7051, 1591, 102]   \n",
       "\n",
       "                            token_type_ids  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1                       [0, 0, 0, 0, 0, 0]   \n",
       "2           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "3                    [0, 0, 0, 0, 0, 0, 0]   \n",
       "4                          [0, 0, 0, 0, 0]   \n",
       "...                                    ...   \n",
       "2608                 [0, 0, 0, 0, 0, 0, 0]   \n",
       "2609                          [0, 0, 0, 0]   \n",
       "2610                          [0, 0, 0, 0]   \n",
       "2611              [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2612                 [0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                            attention_mask  \n",
       "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "1                       [1, 1, 1, 1, 1, 1]  \n",
       "2           [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "3                    [1, 1, 1, 1, 1, 1, 1]  \n",
       "4                          [1, 1, 1, 1, 1]  \n",
       "...                                    ...  \n",
       "2608                 [1, 1, 1, 1, 1, 1, 1]  \n",
       "2609                          [1, 1, 1, 1]  \n",
       "2610                          [1, 1, 1, 1]  \n",
       "2611              [1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "2612                 [1, 1, 1, 1, 1, 1, 1]  \n",
       "\n",
       "[2613 rows x 4 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(examples):\n",
    "    return tokenizer(examples['text'], truncation=True)\n",
    "\n",
    "train_ds = ds['train'].map(\n",
    "    tokenize, \n",
    "    batched=True,\n",
    "    remove_columns=['text'],\n",
    "    # remove_columns=['title', 'description', 'text'],\n",
    ")\n",
    "eval_ds = ds['validation'].map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    "    remove_columns=['text'],\n",
    "    # remove_columns=['title', 'description', 'text'],\n",
    ")\n",
    "train_ds.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca78a0b",
   "metadata": {},
   "source": [
    "Create the transformer model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "36846278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from transformers.models.bert.modeling_bert import BertModel, BertPreTrainedModel\n",
    "\n",
    "# https://github.com/huggingface/transformers/blob/65659a29cf5a079842e61a63d57fa24474288998/src/transformers/models/bert/modeling_bert.py#L1486\n",
    "\n",
    "class BertForSequenceClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            **kwargs,\n",
    "        )\n",
    "        cls_outputs = outputs.last_hidden_state[:, 0, :]\n",
    "        cls_outputs = self.dropout(cls_outputs)\n",
    "        logits = self.classifier(cls_outputs)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b15ac966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    transformer_name,\n",
    "    num_labels=len(labels),\n",
    "    # num_labels=2\n",
    ")\n",
    "\n",
    "model = (\n",
    "    BertForSequenceClassification\n",
    "    .from_pretrained(transformer_name, config=config)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae1a93c",
   "metadata": {},
   "source": [
    "Create the trainer object and train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6d805f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "num_epochs = 2\n",
    "batch_size = 24\n",
    "weight_decay = 0.01\n",
    "model_name = f'{transformer_name}-sequence-classification'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name,\n",
    "    log_level='error',\n",
    "    num_train_epochs=num_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    evaluation_strategy='epoch',\n",
    "    weight_decay=weight_decay,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "77a0699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    y_true = eval_pred.label_ids\n",
    "    y_pred = np.argmax(eval_pred.predictions, axis=-1)\n",
    "    return {'accuracy': accuracy_score(y_true, y_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6c16ead2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1261/485909320.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "301aefd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3257763981819153, 'eval_accuracy': 0.8715596330275229, 'eval_runtime': 0.6209, 'eval_samples_per_second': 526.629, 'eval_steps_per_second': 22.547, 'epoch': 1.0}\n",
      "{'eval_loss': 0.32719868421554565, 'eval_accuracy': 0.8807339449541285, 'eval_runtime': 0.5515, 'eval_samples_per_second': 592.891, 'eval_steps_per_second': 25.384, 'epoch': 2.0}\n",
      "{'train_runtime': 43.2016, 'train_samples_per_second': 120.968, 'train_steps_per_second': 5.046, 'train_loss': 0.43179604766565727, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=218, training_loss=0.43179604766565727, metrics={'train_runtime': 43.2016, 'train_samples_per_second': 120.968, 'train_steps_per_second': 5.046, 'train_loss': 0.43179604766565727, 'epoch': 2.0})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1ec029",
   "metadata": {},
   "source": [
    "Evaluate on the test partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fa4b892f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109bb03504f144878c1aec814735fc12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/327 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 8147, 1268, 102]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 1185, 189, 1204, 4268, 131, 113, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[101, 9367, 1103, 1342, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 18732, 25290, 11680, 2137, 22157, 157, 3...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 1142, 1110, 1136, 1139, 8750, 6088, 1120...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 5671, 1159, 102]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 1274, 1204, 1400, 1155, 8750, 1285, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 190, 1274, 1204, 1444, 4035, 23655, 2737...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 188, 1616, 14166, 1568, 1591, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 192, 1604, 123, 1167, 2673, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>327 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                          input_ids  \\\n",
       "0        0                             [101, 8147, 1268, 102]   \n",
       "1        0        [101, 1185, 189, 1204, 4268, 131, 113, 102]   \n",
       "2        2                       [101, 9367, 1103, 1342, 102]   \n",
       "3        0  [101, 18732, 25290, 11680, 2137, 22157, 157, 3...   \n",
       "4        1  [101, 1142, 1110, 1136, 1139, 8750, 6088, 1120...   \n",
       "..     ...                                                ...   \n",
       "322      0                             [101, 5671, 1159, 102]   \n",
       "323      1     [101, 1274, 1204, 1400, 1155, 8750, 1285, 102]   \n",
       "324      0  [101, 190, 1274, 1204, 1444, 4035, 23655, 2737...   \n",
       "325      0           [101, 188, 1616, 14166, 1568, 1591, 102]   \n",
       "326      1             [101, 192, 1604, 123, 1167, 2673, 102]   \n",
       "\n",
       "                              token_type_ids  \\\n",
       "0                               [0, 0, 0, 0]   \n",
       "1                   [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2                            [0, 0, 0, 0, 0]   \n",
       "3                [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "4             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "..                                       ...   \n",
       "322                             [0, 0, 0, 0]   \n",
       "323                 [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "324  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "325                    [0, 0, 0, 0, 0, 0, 0]   \n",
       "326                    [0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                              attention_mask  \n",
       "0                               [1, 1, 1, 1]  \n",
       "1                   [1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "2                            [1, 1, 1, 1, 1]  \n",
       "3                [1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "4             [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "..                                       ...  \n",
       "322                             [1, 1, 1, 1]  \n",
       "323                 [1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "324  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "325                    [1, 1, 1, 1, 1, 1, 1]  \n",
       "326                    [1, 1, 1, 1, 1, 1, 1]  \n",
       "\n",
       "[327 rows x 4 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds = ds['test'].map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    "    remove_columns=['text'],\n",
    "    # remove_columns=['title', 'description', 'text'],\n",
    ")\n",
    "test_ds.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7fe018fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 4.580799  , -2.868516  , -2.6602206 ],\n",
       "       [ 4.189622  , -2.6161432 , -2.344411  ],\n",
       "       [-2.5880606 ,  3.3795323 , -0.8629769 ],\n",
       "       [ 3.7426946 , -2.9373856 , -2.0525022 ],\n",
       "       [-2.2710679 ,  2.836999  , -0.9064354 ],\n",
       "       [-2.9694412 ,  2.9193392 , -0.19312295],\n",
       "       [ 4.3639402 , -3.2938905 , -2.410439  ],\n",
       "       [-2.7103593 , -0.68810624,  2.5079951 ],\n",
       "       [ 4.7041464 , -3.598425  , -1.9860016 ],\n",
       "       [ 3.8959372 , -2.6260152 , -2.0801125 ],\n",
       "       [-0.28866628, -1.4368327 ,  0.53579104],\n",
       "       [ 3.7710135 , -3.0539846 , -1.1221324 ],\n",
       "       [-3.5330162 ,  0.04097487,  2.9096947 ],\n",
       "       [ 4.0402822 , -3.3952386 , -1.7955227 ],\n",
       "       [ 4.7021914 , -3.339149  , -2.3963218 ],\n",
       "       [-3.2164176 ,  2.984665  , -0.2384363 ],\n",
       "       [ 4.509323  , -3.897624  , -2.073632  ],\n",
       "       [ 3.774676  , -3.4613605 , -1.9652206 ],\n",
       "       [-3.422785  , -0.53170866,  3.1443765 ],\n",
       "       [-3.1404371 , -0.8161251 ,  2.8167133 ],\n",
       "       [-3.2455702 ,  1.1609881 ,  1.5115793 ],\n",
       "       [-2.2553918 , -0.35966584,  1.9267646 ],\n",
       "       [ 4.543633  , -3.7504368 , -2.2945862 ],\n",
       "       [ 4.244237  , -3.6556435 , -1.8905396 ],\n",
       "       [ 4.640704  , -3.5843024 , -2.3023572 ],\n",
       "       [ 2.1758525 , -2.7116013 , -0.69129574],\n",
       "       [ 3.5395117 , -2.6596453 , -2.1906781 ],\n",
       "       [ 3.6697497 , -2.8416162 , -1.9425647 ],\n",
       "       [-2.49562   ,  0.5808931 ,  1.6372489 ],\n",
       "       [ 4.5604944 , -3.4444041 , -2.0769432 ],\n",
       "       [-2.8593435 , -1.8662758 ,  3.8651505 ],\n",
       "       [-0.43586114,  2.3387218 , -1.855986  ],\n",
       "       [ 4.7049465 , -3.2283807 , -2.3168857 ],\n",
       "       [-3.4990377 , -0.9358944 ,  3.4267776 ],\n",
       "       [-0.23863599, -0.70591664,  0.78471065],\n",
       "       [-2.7250822 ,  2.1187458 ,  0.28506407],\n",
       "       [-2.9083836 ,  0.14457098,  1.8844707 ],\n",
       "       [-0.3327563 , -0.1249822 ,  0.10453197],\n",
       "       [ 4.193323  , -3.2375104 , -2.3153553 ],\n",
       "       [ 2.081886  , -3.3292189 , -0.44846824],\n",
       "       [ 2.4427197 , -2.166119  , -1.384014  ],\n",
       "       [ 2.1019576 , -2.1744785 , -1.030867  ],\n",
       "       [ 2.6258423 , -2.3894434 , -1.5225776 ],\n",
       "       [ 4.7900314 , -3.8512332 , -2.3909936 ],\n",
       "       [-2.7903187 , -1.6341448 ,  3.903439  ],\n",
       "       [ 4.0751185 , -3.489127  , -1.5765597 ],\n",
       "       [ 2.8812025 , -2.146316  , -1.536278  ],\n",
       "       [-3.2421405 ,  1.1439712 ,  1.5552114 ],\n",
       "       [ 4.207629  , -3.2215953 , -2.3961344 ],\n",
       "       [ 1.0977912 , -1.1572719 , -0.22334322],\n",
       "       [ 2.5267086 , -2.4467058 , -1.0180324 ],\n",
       "       [-2.546414  ,  1.8919274 ,  0.26037616],\n",
       "       [-2.104314  , -0.34153834,  1.6877376 ],\n",
       "       [ 3.1025865 , -2.3921616 , -1.4725457 ],\n",
       "       [ 3.655859  , -3.447988  , -1.4344448 ],\n",
       "       [-2.0498707 ,  3.556694  , -1.5249046 ],\n",
       "       [ 4.3664317 , -3.574915  , -2.06601   ],\n",
       "       [-2.734979  , -0.2921137 ,  1.9375411 ],\n",
       "       [-3.6386755 , -0.33032432,  2.9999237 ],\n",
       "       [ 4.095776  , -3.4528687 , -1.8197006 ],\n",
       "       [-0.7017806 , -1.5649664 ,  1.0988756 ],\n",
       "       [-2.471831  ,  4.1862984 , -1.2848586 ],\n",
       "       [-2.7906408 ,  2.0063279 ,  0.6126298 ],\n",
       "       [ 3.2764244 , -3.0327792 , -1.4584428 ],\n",
       "       [ 0.33899972, -0.87693346, -0.30265728],\n",
       "       [-0.02617938,  0.8703871 , -1.724625  ],\n",
       "       [-2.8206623 ,  0.07371318,  1.2801784 ],\n",
       "       [-3.6865187 , -0.98611313,  3.3660984 ],\n",
       "       [ 4.85351   , -3.8078506 , -2.2184467 ],\n",
       "       [-2.808577  ,  0.95697653,  1.023434  ],\n",
       "       [ 4.65479   , -3.743418  , -2.0872076 ],\n",
       "       [-3.201771  ,  0.42835063,  2.0680811 ],\n",
       "       [ 4.233529  , -3.5409212 , -2.420301  ],\n",
       "       [-3.2185156 ,  3.0052044 , -0.17959763],\n",
       "       [ 2.5819952 , -1.8174028 , -1.806349  ],\n",
       "       [ 3.4195778 , -2.9134436 , -2.1263704 ],\n",
       "       [ 3.728212  , -3.264428  , -2.0289354 ],\n",
       "       [ 0.48521686, -0.5918207 , -0.7391673 ],\n",
       "       [-0.04766361, -0.5293964 , -0.00700454],\n",
       "       [-3.3612044 , -0.71399176,  3.4100115 ],\n",
       "       [ 0.40893152, -1.6075728 ,  1.0354418 ],\n",
       "       [-2.906831  ,  3.0623298 , -0.14293446],\n",
       "       [-2.9825242 , -1.0611337 ,  3.0713265 ],\n",
       "       [ 1.0195483 , -2.0467477 , -0.0303075 ],\n",
       "       [ 4.991274  , -3.9091625 , -2.3524313 ],\n",
       "       [-3.152745  , -1.2110623 ,  3.5856574 ],\n",
       "       [-3.4426358 , -0.80350065,  3.519547  ],\n",
       "       [-1.4460394 , -1.2221283 ,  1.7648033 ],\n",
       "       [ 1.6399027 , -1.9252362 , -1.6443166 ],\n",
       "       [ 0.15507385, -1.2943051 ,  0.19437188],\n",
       "       [ 4.6211934 , -3.054677  , -2.8603475 ],\n",
       "       [ 3.2234654 , -2.8694098 , -2.0385585 ],\n",
       "       [ 3.827754  , -3.1956687 , -2.0252717 ],\n",
       "       [ 4.599956  , -3.3484838 , -2.2009997 ],\n",
       "       [ 3.9735856 , -2.488782  , -2.8462725 ],\n",
       "       [ 3.4428756 , -1.6349016 , -2.6108513 ],\n",
       "       [-0.3590522 , -1.3303492 ,  0.5401603 ],\n",
       "       [-0.7947435 ,  2.7044613 , -1.7242855 ],\n",
       "       [-0.41464654, -0.9892967 ,  0.4933932 ],\n",
       "       [-2.901768  , -1.0225974 ,  3.5266232 ],\n",
       "       [ 4.6647167 , -3.3671517 , -2.2022014 ],\n",
       "       [ 5.0474577 , -3.7606606 , -2.2722561 ],\n",
       "       [ 3.0306194 , -2.3479805 , -1.9195743 ],\n",
       "       [ 4.390368  , -3.3697395 , -2.0512776 ],\n",
       "       [ 2.1916077 , -2.7441406 , -0.60519993],\n",
       "       [ 4.380799  , -3.1725085 , -2.7330256 ],\n",
       "       [-3.9627774 , -0.01977316,  2.8166108 ],\n",
       "       [-2.953962  , -0.12242804,  2.3432899 ],\n",
       "       [-4.167758  ,  0.46485654,  2.4823515 ],\n",
       "       [-2.7197385 , -1.1265454 ,  3.2136784 ],\n",
       "       [ 2.8167815 , -3.007192  , -1.1530195 ],\n",
       "       [-3.742171  , -0.4592223 ,  3.137265  ],\n",
       "       [ 5.0439177 , -3.48304   , -2.39044   ],\n",
       "       [-2.692166  ,  2.6451807 , -0.30597505],\n",
       "       [ 2.7016153 , -2.3600094 , -1.4978032 ],\n",
       "       [-1.2649353 , -1.2668111 ,  1.8208457 ],\n",
       "       [ 1.7513494 , -1.6133863 , -0.9240037 ],\n",
       "       [-3.4634044 ,  0.01620275,  2.425962  ],\n",
       "       [-3.1699383 , -0.11243672,  2.7785814 ],\n",
       "       [ 4.3303566 , -2.5185804 , -2.507104  ],\n",
       "       [ 4.8444567 , -3.7054238 , -2.37955   ],\n",
       "       [-3.0998006 , -1.2459502 ,  3.132584  ],\n",
       "       [ 4.2879567 , -3.0739837 , -2.2795157 ],\n",
       "       [-1.6160914 ,  3.0487769 , -1.3491248 ],\n",
       "       [-3.680297  ,  2.2796378 ,  0.96040034],\n",
       "       [ 3.7289135 , -3.425848  , -1.6749468 ],\n",
       "       [-3.3978531 ,  2.4803982 ,  0.12390187],\n",
       "       [ 2.858606  , -3.0549417 , -1.3349708 ],\n",
       "       [-2.2413068 ,  0.4799948 ,  1.1657176 ],\n",
       "       [ 4.4415016 , -3.2939425 , -2.5575314 ],\n",
       "       [-3.1685865 ,  0.37959963,  1.6056765 ],\n",
       "       [ 4.5960455 , -3.158688  , -2.20227   ],\n",
       "       [ 4.4276667 , -3.6043327 , -2.2428057 ],\n",
       "       [-0.9560736 , -0.7717731 ,  0.83846885],\n",
       "       [ 4.153983  , -3.4507241 , -1.948875  ],\n",
       "       [-2.602692  ,  0.7066193 ,  0.82609874],\n",
       "       [ 2.7901602 , -2.76236   , -0.99369377],\n",
       "       [ 4.10167   , -3.6530662 , -2.355117  ],\n",
       "       [ 3.687917  , -3.2500238 , -1.6675467 ],\n",
       "       [ 0.6120635 , -3.0369387 ,  0.37782177],\n",
       "       [ 2.7211928 , -2.9269397 , -1.3158492 ],\n",
       "       [ 4.7049465 , -3.2283812 , -2.316886  ],\n",
       "       [ 5.196201  , -3.3757067 , -2.6950455 ],\n",
       "       [ 4.612286  , -3.11405   , -2.2998452 ],\n",
       "       [ 4.05637   , -3.6412492 , -1.9915112 ],\n",
       "       [ 4.4625235 , -3.071598  , -2.6615958 ],\n",
       "       [ 4.867564  , -2.8574467 , -3.1150398 ],\n",
       "       [-2.5774467 ,  1.8912715 ,  0.24166858],\n",
       "       [-3.447711  , -0.9211878 ,  3.5015616 ],\n",
       "       [-3.0737169 , -0.6721351 ,  3.1375163 ],\n",
       "       [-2.2012305 ,  0.5427572 ,  0.3620918 ],\n",
       "       [-1.8256304 , -0.9686929 ,  1.9919088 ],\n",
       "       [ 2.6236386 , -2.5250626 , -1.1125375 ],\n",
       "       [ 4.0462666 , -3.119148  , -1.8329836 ],\n",
       "       [ 2.664999  , -1.4849584 , -2.0839891 ],\n",
       "       [-2.6239278 , -0.07034282,  1.9430727 ],\n",
       "       [ 3.859028  , -3.3262634 , -1.8621668 ],\n",
       "       [ 0.57031536, -1.8354175 ,  0.3022754 ],\n",
       "       [-3.1155624 , -0.92489064,  2.8751645 ],\n",
       "       [ 2.276953  , -1.4236679 , -1.8908658 ],\n",
       "       [-3.4281821 , -0.44916293,  3.3408985 ],\n",
       "       [-3.3037853 , -1.1409893 ,  3.5460958 ],\n",
       "       [ 4.192067  , -2.95332   , -2.313185  ],\n",
       "       [-2.5025034 , -1.0481111 ,  2.9607327 ],\n",
       "       [ 4.5893497 , -3.1386142 , -2.576645  ],\n",
       "       [ 2.0334604 , -3.4052694 , -0.49793395],\n",
       "       [-3.0495536 , -0.8055788 ,  3.2625487 ],\n",
       "       [-3.5429368 , -1.0412439 ,  3.6155543 ],\n",
       "       [ 4.6839952 , -3.367443  , -2.5572436 ],\n",
       "       [-2.8723762 ,  2.4468393 ,  0.01512266],\n",
       "       [ 3.020364  , -1.9209256 , -2.0365415 ],\n",
       "       [ 3.0790083 , -2.3404384 , -1.9051287 ],\n",
       "       [-0.46539906,  2.6359103 , -1.9223485 ],\n",
       "       [-2.9930649 ,  3.57474   , -0.3196937 ],\n",
       "       [-3.0140612 ,  0.2880607 ,  1.8458507 ],\n",
       "       [ 0.07972412, -1.3019518 , -0.03521302],\n",
       "       [ 3.9441931 , -2.6754165 , -1.921663  ],\n",
       "       [ 3.6485782 , -3.0353565 , -2.0457077 ],\n",
       "       [ 2.817084  , -2.7053015 , -1.9503812 ],\n",
       "       [-3.342086  , -1.5443884 ,  3.8260899 ],\n",
       "       [ 1.1610632 , -1.6787832 , -0.713848  ],\n",
       "       [ 4.4325542 , -3.168151  , -2.2997768 ],\n",
       "       [-3.366817  , -0.36988518,  2.78657   ],\n",
       "       [-2.5106215 ,  3.0109842 , -0.3726286 ],\n",
       "       [ 4.5893507 , -3.1386137 , -2.576645  ],\n",
       "       [-2.2346232 , -0.04003846,  1.9202033 ],\n",
       "       [-1.9474103 , -0.8781035 ,  1.765571  ],\n",
       "       [ 3.8890886 , -3.265559  , -2.04138   ],\n",
       "       [-1.9440851 ,  4.0315657 , -1.5279981 ],\n",
       "       [-3.7625277 ,  2.0936546 ,  1.1260022 ],\n",
       "       [ 4.9631653 , -3.706994  , -2.5840774 ],\n",
       "       [ 3.9593637 , -3.3625708 , -1.8371993 ],\n",
       "       [-3.1121647 , -1.3480499 ,  3.6500049 ],\n",
       "       [-3.416901  ,  1.0219963 ,  2.0242746 ],\n",
       "       [-2.0563753 , -1.0270534 ,  2.0641325 ],\n",
       "       [-3.6171584 , -0.14977708,  2.917028  ],\n",
       "       [ 4.529316  , -3.3158288 , -2.5052862 ],\n",
       "       [-0.568125  ,  2.436697  , -1.809389  ],\n",
       "       [ 3.2834938 , -2.9004638 , -1.5878183 ],\n",
       "       [ 4.590948  , -3.6107416 , -2.3862622 ],\n",
       "       [ 4.3862324 , -3.7832923 , -1.8023969 ],\n",
       "       [-3.458346  ,  1.1138092 ,  1.77472   ],\n",
       "       [-3.9627767 , -0.01977272,  2.8166108 ],\n",
       "       [-4.173208  ,  1.3640172 ,  1.6237942 ],\n",
       "       [-2.3002024 , -0.6418811 ,  2.0455525 ],\n",
       "       [-1.8881468 , -0.48341206,  1.3904115 ],\n",
       "       [-1.2894807 , -1.1499836 ,  1.0597888 ],\n",
       "       [ 4.3193836 , -3.3642025 , -2.453935  ],\n",
       "       [ 4.514962  , -3.0563383 , -2.3587618 ],\n",
       "       [ 4.122963  , -3.4522223 , -1.789004  ],\n",
       "       [-0.76051325, -1.4659371 ,  1.1169404 ],\n",
       "       [-2.2872918 ,  3.684435  , -1.297997  ],\n",
       "       [-1.2693162 ,  0.5984509 ,  0.25417772],\n",
       "       [-2.210988  , -0.23007473,  1.8928705 ],\n",
       "       [ 4.5991497 , -3.8965812 , -1.9633235 ],\n",
       "       [ 4.8112364 , -3.2876525 , -2.7389803 ],\n",
       "       [ 4.896862  , -3.6596358 , -2.198637  ],\n",
       "       [ 4.304964  , -3.7448566 , -1.7670403 ],\n",
       "       [ 4.615532  , -3.5911448 , -2.2662601 ],\n",
       "       [-0.45582342,  1.5477251 , -1.4354073 ],\n",
       "       [-2.8953016 ,  2.0564265 ,  0.48039022],\n",
       "       [-2.1465762 ,  1.8674674 ,  0.14364448],\n",
       "       [-3.9446385 , -0.01026184,  2.8234308 ],\n",
       "       [-3.8061292 ,  0.05789495,  2.767399  ],\n",
       "       [-3.0012634 ,  1.9334146 ,  0.53423655],\n",
       "       [ 3.8410594 , -2.5420847 , -2.396119  ],\n",
       "       [ 3.6105726 , -3.067442  , -1.8162907 ],\n",
       "       [-2.2686641 ,  3.988284  , -1.5387552 ],\n",
       "       [-1.8898325 , -0.8540472 ,  2.0784218 ],\n",
       "       [ 2.1062772 , -2.2234843 , -1.359506  ],\n",
       "       [ 4.3316054 , -3.324535  , -2.2191868 ],\n",
       "       [ 3.5591645 , -3.0039241 , -1.8295351 ],\n",
       "       [ 4.3884287 , -3.6181257 , -2.168312  ],\n",
       "       [ 2.904883  , -3.8550897 , -0.770071  ],\n",
       "       [-2.3851268 ,  3.7965999 , -1.5757427 ],\n",
       "       [ 4.6749253 , -3.222972  , -2.5708377 ],\n",
       "       [ 3.84013   , -3.52245   , -1.880832  ],\n",
       "       [-3.4144504 ,  0.29010913,  2.6800694 ],\n",
       "       [ 4.551265  , -3.6540837 , -2.3175747 ],\n",
       "       [ 2.3836935 , -2.1804338 , -0.92234194],\n",
       "       [ 3.7372692 , -3.1885383 , -1.3518373 ],\n",
       "       [-1.849556  , -1.0826266 ,  2.031972  ],\n",
       "       [ 0.53044474, -1.9386832 ,  0.11321542],\n",
       "       [ 3.2069745 , -2.6970859 , -1.6140659 ],\n",
       "       [ 3.721457  , -2.3714063 , -2.4643724 ],\n",
       "       [ 3.6062675 , -2.7967649 , -2.3601007 ],\n",
       "       [ 1.9819064 , -1.7918234 , -0.9197507 ],\n",
       "       [-3.6671944 ,  0.70973146,  1.935027  ],\n",
       "       [ 4.5481815 , -3.2134645 , -2.6428711 ],\n",
       "       [ 4.4897165 , -3.4706445 , -2.2539449 ],\n",
       "       [-2.848235  , -1.633742  ,  3.671725  ],\n",
       "       [ 3.8190582 , -3.4466414 , -1.9173671 ],\n",
       "       [-3.7803419 ,  2.5998876 ,  0.51570576],\n",
       "       [ 0.02955523,  0.1222068 , -0.96133304],\n",
       "       [-3.8039825 ,  1.7248275 ,  1.345806  ],\n",
       "       [-2.9176004 ,  2.9159467 , -0.09357191],\n",
       "       [-3.018882  , -1.4960532 ,  3.910602  ],\n",
       "       [ 1.2848375 , -1.3075349 , -1.1883371 ],\n",
       "       [ 2.187825  , -2.8125052 , -0.58252   ],\n",
       "       [ 3.7085917 , -2.9534154 , -2.2479312 ],\n",
       "       [-2.062125  ,  0.38343462,  0.1230121 ],\n",
       "       [ 4.4423285 , -3.6550236 , -2.3763328 ],\n",
       "       [ 1.5509655 , -2.176506  , -0.08058504],\n",
       "       [-2.7318697 ,  2.4264686 , -0.26276186],\n",
       "       [ 0.9789052 , -2.3449733 , -0.25439057],\n",
       "       [ 3.4088712 , -2.0404038 , -2.4932516 ],\n",
       "       [-3.6712933 ,  1.651367  ,  1.1514386 ],\n",
       "       [ 4.588828  , -2.8443842 , -2.6789422 ],\n",
       "       [-3.1685326 , -0.04538317,  2.5946527 ],\n",
       "       [-3.6441123 ,  0.17169489,  2.2642255 ],\n",
       "       [-3.0371695 , -0.45902535,  2.4021082 ],\n",
       "       [-2.85409   ,  3.3716884 , -0.9382399 ],\n",
       "       [-3.4987128 , -0.46955344,  3.0534797 ],\n",
       "       [ 2.2089784 , -2.7490416 , -0.5350499 ],\n",
       "       [ 4.52802   , -2.9325223 , -2.3034573 ],\n",
       "       [ 2.8206391 , -3.5200784 , -0.7455876 ],\n",
       "       [ 3.0634038 , -2.7721553 , -1.4507781 ],\n",
       "       [-2.6418931 , -0.4446335 ,  2.2831025 ],\n",
       "       [-1.882263  , -0.62538815,  1.8525914 ],\n",
       "       [-3.8394086 ,  0.5079105 ,  2.3144522 ],\n",
       "       [ 4.1028204 , -3.2793572 , -2.0864341 ],\n",
       "       [ 4.654915  , -3.4285274 , -2.43292   ],\n",
       "       [-1.7993028 ,  1.4670913 ,  0.20514196],\n",
       "       [ 4.7486277 , -3.0618863 , -2.6810834 ],\n",
       "       [-2.3633769 ,  0.5827117 ,  1.3283159 ],\n",
       "       [-2.580431  ,  2.902343  , -0.93196654],\n",
       "       [-3.3950114 ,  0.961627  ,  1.8723334 ],\n",
       "       [ 4.6760526 , -3.158442  , -2.6264713 ],\n",
       "       [-2.95944   ,  2.7583497 , -0.10220062],\n",
       "       [ 4.463715  , -3.4571772 , -2.3012476 ],\n",
       "       [ 4.0131483 , -3.3881402 , -1.9650668 ],\n",
       "       [-3.3098261 , -1.3608203 ,  3.8341684 ],\n",
       "       [ 4.575414  , -3.512858  , -2.5895364 ],\n",
       "       [-3.7089276 ,  0.11932911,  3.012832  ],\n",
       "       [ 4.0472355 , -2.756158  , -2.5435772 ],\n",
       "       [ 4.7697215 , -3.4359062 , -2.377912  ],\n",
       "       [-4.0793    ,  0.5758778 ,  2.4105344 ],\n",
       "       [ 4.252361  , -3.5639863 , -1.8399075 ],\n",
       "       [ 4.777     , -3.3542726 , -2.3563182 ],\n",
       "       [-3.5885398 ,  0.314295  ,  2.5983644 ],\n",
       "       [ 4.571106  , -3.2543268 , -2.3828733 ],\n",
       "       [ 4.212871  , -3.2012262 , -2.3945374 ],\n",
       "       [-2.6250172 , -0.1291892 ,  1.9436548 ],\n",
       "       [ 0.25868213,  0.5345336 , -1.5841577 ],\n",
       "       [-3.620135  ,  0.5240921 ,  2.451666  ],\n",
       "       [ 0.8531993 , -2.0703933 , -0.4819559 ],\n",
       "       [ 4.000378  , -3.1641977 , -1.9801362 ],\n",
       "       [ 4.709177  , -3.5803154 , -1.95745   ],\n",
       "       [ 4.729965  , -3.0185583 , -2.5982924 ],\n",
       "       [-3.6848567 ,  3.3794372 ,  0.34813645],\n",
       "       [ 3.3113024 , -3.2018979 , -0.9829878 ],\n",
       "       [ 4.190927  , -2.7843094 , -2.4234343 ],\n",
       "       [ 4.485616  , -3.0821013 , -2.480511  ],\n",
       "       [ 4.44191   , -3.1020641 , -2.414041  ],\n",
       "       [ 4.156327  , -2.626634  , -2.169941  ],\n",
       "       [ 4.8449492 , -3.5819516 , -2.5323787 ],\n",
       "       [ 4.694609  , -2.8200724 , -2.642828  ],\n",
       "       [ 4.86617   , -3.2330856 , -2.669687  ],\n",
       "       [-2.5792258 , -0.9268279 ,  2.9360135 ],\n",
       "       [ 4.4640946 , -2.6995013 , -2.6669595 ],\n",
       "       [ 0.4659523 , -1.9882028 ,  0.19223183],\n",
       "       [-2.4508693 ,  0.07625905,  2.0822656 ],\n",
       "       [ 4.6352587 , -3.650668  , -2.4691234 ],\n",
       "       [-2.384056  ,  3.593547  , -1.6736871 ],\n",
       "       [ 3.8947527 , -2.886849  , -2.4774837 ],\n",
       "       [ 1.4804082 , -2.1357694 , -0.14466915],\n",
       "       [ 0.5062148 ,  0.05463265, -2.068211  ]], dtype=float32), label_ids=array([0, 0, 2, 0, 1, 1, 0, 2, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 2, 2, 0, 2,\n",
       "       0, 0, 0, 0, 0, 0, 2, 0, 2, 1, 0, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "       2, 0, 0, 2, 0, 0, 1, 1, 2, 0, 0, 2, 0, 2, 2, 0, 2, 1, 2, 0, 2, 0,\n",
       "       2, 2, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 2, 2, 0, 1, 2, 0, 0, 2, 2, 2,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2,\n",
       "       1, 2, 0, 1, 0, 2, 0, 1, 2, 0, 0, 2, 0, 1, 1, 0, 1, 0, 2, 0, 2, 0,\n",
       "       0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0,\n",
       "       0, 2, 0, 2, 2, 1, 2, 1, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 1, 1, 2, 0,\n",
       "       0, 0, 0, 2, 0, 0, 2, 1, 0, 2, 2, 0, 1, 2, 0, 0, 2, 2, 2, 2, 0, 1,\n",
       "       2, 0, 0, 2, 1, 1, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 2, 2, 1, 0, 0, 1, 2, 0, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 2,\n",
       "       2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 1, 1, 2, 1, 2, 0, 0, 0, 2, 0, 2, 1,\n",
       "       0, 0, 1, 0, 2, 2, 2, 1, 2, 0, 0, 0, 0, 2, 2, 2, 0, 0, 2, 0, 2, 1,\n",
       "       1, 0, 1, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 1, 2, 0, 1, 2, 2, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 1, 0, 0, 1]), metrics={'test_loss': 0.38693931698799133, 'test_accuracy': 0.8715596330275229, 'test_runtime': 0.5255, 'test_samples_per_second': 622.291, 'test_steps_per_second': 26.642})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = trainer.predict(test_ds)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "14221494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not toxic       0.94      0.93      0.94       180\n",
      " kinda toxic       0.73      0.75      0.74        48\n",
      "       toxic       0.82      0.82      0.82        99\n",
      "\n",
      "    accuracy                           0.87       327\n",
      "   macro avg       0.83      0.83      0.83       327\n",
      "weighted avg       0.87      0.87      0.87       327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = output.label_ids\n",
    "y_pred = np.argmax(output.predictions, axis=-1)\n",
    "target_names = [\"not toxic\",\"kinda toxic\",\"toxic\"]\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f432b9-1f2b-4eee-ad78-2eb489fd32a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
