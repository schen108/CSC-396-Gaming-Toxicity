{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56c031b5",
   "metadata": {},
   "source": [
    "# Text Classification Using Transformer Networks (BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40bd59e",
   "metadata": {},
   "source": [
    "Some initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "133ffdc9-f28b-46fa-84ee-19ded042aaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.26.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.47.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.26.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (2.5.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (0.26.5)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.47.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.26.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install datasets\n",
    "!pip3 install transformers\n",
    "!pip install -U accelerate\n",
    "!pip install -U transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3afe3bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "random seed: 1234\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# enable tqdm in pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# set to True to use the gpu (if there is one available)\n",
    "use_gpu = True\n",
    "\n",
    "# select device\n",
    "device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')\n",
    "print(f'device: {device.type}')\n",
    "\n",
    "# random seed\n",
    "seed = 1234\n",
    "\n",
    "# set random seed\n",
    "if seed is not None:\n",
    "    print(f'random seed: {seed}')\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3441f3",
   "metadata": {},
   "source": [
    "Read the train/dev/test datasets and create a HuggingFace `Dataset` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1885c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_league_data(filename):\n",
    "    # read csv file\n",
    "    df = pd.read_csv(filename, header=0)\n",
    "    # Get only the text and label columns\n",
    "    return df[[\"message\",\"toxicity_label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d03f51a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>report for unskilled player is useless thx &lt;3 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mimimi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im comming for you riven pfft focus Zed always...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thx top no flash for what ? he has 2 kill in l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IIII ISI K udyr top dnt us see it? CAMP MORE P...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88083</th>\n",
       "      <td>gj &amp;gt;&amp;lt; xD i said ss gj stop go alone plz ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88084</th>\n",
       "      <td>i like the new un-do button GET BACK GET BACK ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88085</th>\n",
       "      <td>thx now i can b its ok re top sry thought cait...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88086</th>\n",
       "      <td>take t brb swian i was ogin b i was going blue...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88087</th>\n",
       "      <td>much farm lulu at top? ty need blue push op i ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88088 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 message  label\n",
       "0      report for unskilled player is useless thx <3 ...      0\n",
       "1                                                 mimimi      0\n",
       "2      im comming for you riven pfft focus Zed always...      1\n",
       "3      thx top no flash for what ? he has 2 kill in l...      1\n",
       "4      IIII ISI K udyr top dnt us see it? CAMP MORE P...      0\n",
       "...                                                  ...    ...\n",
       "88083  gj &gt;&lt; xD i said ss gj stop go alone plz ...      1\n",
       "88084  i like the new un-do button GET BACK GET BACK ...      1\n",
       "88085  thx now i can b its ok re top sry thought cait...      0\n",
       "88086  take t brb swian i was ogin b i was going blue...      1\n",
       "88087  much farm lulu at top? ty need blue push op i ...      0\n",
       "\n",
       "[88088 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labels = open('classes.txt').read().splitlines()\n",
    "labels=[\"0\",\"1\"]\n",
    "league_data = read_league_data('dataToxic.csv')\n",
    "print(labels)\n",
    "league_data = league_data.rename(columns={\"toxicity_label\": \"label\"})\n",
    "league_data['message'] = league_data['message'].str.replace(',',' ',regex=False)\n",
    "league_data['label'] = league_data['label'].apply(lambda x: 1 if x == 'toxic' else 0)\n",
    "league_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5816b20d-ebd5-4605-a674-36e05143b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_kaggle_data(filename):\n",
    "    # read csv file\n",
    "    df = pd.read_csv(filename, header=0)\n",
    "    # Get only the text and label columns\n",
    "    return df[[\"Text\",\"oh_label\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba4670f4-2fc9-4903-bfea-d7b182ae02eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"You fuck your dad.\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"i really don't understand your point.\\xa0 It ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"A\\\\xc2\\\\xa0majority of Canadians can and has ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"listen if you dont wanna get married to a man...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8794</th>\n",
       "      <td>\"Never really gave it much thought. I just fig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8795</th>\n",
       "      <td>\"Nadie se salva de la regla 34 xd\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8796</th>\n",
       "      <td>\"Question: Are you a boy or a girl?\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8797</th>\n",
       "      <td>\"Leave your email or phone number and maybe yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8798</th>\n",
       "      <td>\"From the scenarios you present, I see you bel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8799 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                message  label\n",
       "0                                  \"You fuck your dad.\"      1\n",
       "1     \"i really don't understand your point.\\xa0 It ...      0\n",
       "2     \"A\\\\xc2\\\\xa0majority of Canadians can and has ...      0\n",
       "3     \"listen if you dont wanna get married to a man...      0\n",
       "4     \"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...      0\n",
       "...                                                 ...    ...\n",
       "8794  \"Never really gave it much thought. I just fig...      0\n",
       "8795                 \"Nadie se salva de la regla 34 xd\"      0\n",
       "8796               \"Question: Are you a boy or a girl?\"      0\n",
       "8797  \"Leave your email or phone number and maybe yo...      1\n",
       "8798  \"From the scenarios you present, I see you bel...      0\n",
       "\n",
       "[8799 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_data = read_kaggle_data(\"kaggle_parsed_dataset.csv\")\n",
    "kaggle_data = kaggle_data.rename(columns={\"oh_label\": \"label\", \"Text\": \"message\"})\n",
    "kaggle_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cdc43ff-0989-4a5d-8ae8-bcc924057859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"You fuck your dad.\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"i really don't understand your point.\\xa0 It ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"A\\\\xc2\\\\xa0majority of Canadians can and has ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"listen if you dont wanna get married to a man...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88083</th>\n",
       "      <td>gj &amp;gt;&amp;lt; xD i said ss gj stop go alone plz ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88084</th>\n",
       "      <td>i like the new un-do button GET BACK GET BACK ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88085</th>\n",
       "      <td>thx now i can b its ok re top sry thought cait...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88086</th>\n",
       "      <td>take t brb swian i was ogin b i was going blue...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88087</th>\n",
       "      <td>much farm lulu at top? ty need blue push op i ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96887 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 message  label\n",
       "0                                   \"You fuck your dad.\"      1\n",
       "1      \"i really don't understand your point.\\xa0 It ...      0\n",
       "2      \"A\\\\xc2\\\\xa0majority of Canadians can and has ...      0\n",
       "3      \"listen if you dont wanna get married to a man...      0\n",
       "4      \"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...      0\n",
       "...                                                  ...    ...\n",
       "88083  gj &gt;&lt; xD i said ss gj stop go alone plz ...      1\n",
       "88084  i like the new un-do button GET BACK GET BACK ...      1\n",
       "88085  thx now i can b its ok re top sry thought cait...      0\n",
       "88086  take t brb swian i was ogin b i was going blue...      1\n",
       "88087  much farm lulu at top? ty need blue push op i ...      0\n",
       "\n",
       "[96887 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = pd.concat([kaggle_data,league_data])\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7518aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rows: 77,509\n",
      "eval rows: 9,689\n",
      "test rows: 9,689\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, eval_and_test_df = train_test_split(data, train_size=0.8, random_state\n",
    "= 4)\n",
    "eval_df, test_df = train_test_split(eval_and_test_df, train_size=0.5, random_state = 4)\n",
    "train_df.reset_index(inplace=True, drop=True)\n",
    "eval_df.reset_index(inplace=True, drop=True)\n",
    "test_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(f'train rows: {len(train_df.index):,}')\n",
    "print(f'eval rows: {len(eval_df.index):,}')\n",
    "print(f'test rows: {len(test_df.index):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b3c727f-1bef-45b8-a179-f4b3bcd974c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gg wp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>don't wait not gnking double riven HAHA u suck...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it's my promotion to gold pls play well and do...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 cool for dat ward4 FUCK re j4 blue) gg they ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this patch :D wtf bush! lol udyr :D ward y chill!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9684</th>\n",
       "      <td>ss gj ty gj gj ss puta rammus ss mid b gj gj t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9685</th>\n",
       "      <td>come bot ty invade? oh sorry yes we can he is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9686</th>\n",
       "      <td>cover red just going to ward wtf this pull shy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9687</th>\n",
       "      <td>gg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9688</th>\n",
       "      <td>\"Are you an Egyptian Copt?\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9689 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                message  label\n",
       "0                                                 gg wp      0\n",
       "1     don't wait not gnking double riven HAHA u suck...      1\n",
       "2     it's my promotion to gold pls play well and do...      1\n",
       "3     2 cool for dat ward4 FUCK re j4 blue) gg they ...      0\n",
       "4     this patch :D wtf bush! lol udyr :D ward y chill!      0\n",
       "...                                                 ...    ...\n",
       "9684  ss gj ty gj gj ss puta rammus ss mid b gj gj t...      0\n",
       "9685  come bot ty invade? oh sorry yes we can he is ...      1\n",
       "9686  cover red just going to ward wtf this pull shy...      1\n",
       "9687                                                 gg      0\n",
       "9688                        \"Are you an Egyptian Copt?\"      0\n",
       "\n",
       "[9689 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e06f040b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['message', 'label'],\n",
       "        num_rows: 77509\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['message', 'label'],\n",
       "        num_rows: 9689\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['message', 'label'],\n",
       "        num_rows: 9689\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "ds = DatasetDict()\n",
    "ds['train'] = Dataset.from_pandas(train_df)\n",
    "ds['validation'] = Dataset.from_pandas(eval_df)\n",
    "ds['test'] = Dataset.from_pandas(test_df)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac23185a",
   "metadata": {},
   "source": [
    "Tokenize the texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65e8d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertModel, AutoTokenizer\n",
    "model = AlbertModel.from_pretrained(\"albert/albert-base-v1\", torch_dtype=torch.float16, attn_implementation=\"sdpa\")\n",
    "\n",
    "transformer_name = 'albert-base-v1'\n",
    "tokenizer = AutoTokenizer.from_pretrained(transformer_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52a2caf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe4d3dca9f04d9f880d0a005bb7cf58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/77509 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13737c2f85f47e888c8a9503509794b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9689 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[2, 13, 911, 11128, 1049, 1131, 162, 2843, 119...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[2, 13, 15530, 60, 3979, 4000, 333, 13, 7337, 3]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[2, 680, 880, 20, 3421, 1643, 86, 896, 3851, 2...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[2, 3617, 58, 3617, 58, 13, 45, 118, 13, 18, 6...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[2, 1875, 51, 2620, 13, 10165, 797, 86, 1875, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77504</th>\n",
       "      <td>1</td>\n",
       "      <td>[2, 2210, 8262, 17, 555, 3755, 9, 9, 9, 13, 20...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77505</th>\n",
       "      <td>1</td>\n",
       "      <td>[2, 2593, 11491, 2119, 13, 45, 1569, 255, 38, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77506</th>\n",
       "      <td>1</td>\n",
       "      <td>[2, 489, 728, 13, 20248, 489, 728, 448, 5873, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77507</th>\n",
       "      <td>1</td>\n",
       "      <td>[2, 90, 1679, 31, 221, 22, 38, 76, 778, 43, 40...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77508</th>\n",
       "      <td>1</td>\n",
       "      <td>[2, 21, 15298, 448, 705, 24, 63, 90, 485, 160,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77509 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                          input_ids  \\\n",
       "0          1  [2, 13, 911, 11128, 1049, 1131, 162, 2843, 119...   \n",
       "1          0   [2, 13, 15530, 60, 3979, 4000, 333, 13, 7337, 3]   \n",
       "2          0  [2, 680, 880, 20, 3421, 1643, 86, 896, 3851, 2...   \n",
       "3          0  [2, 3617, 58, 3617, 58, 13, 45, 118, 13, 18, 6...   \n",
       "4          1  [2, 1875, 51, 2620, 13, 10165, 797, 86, 1875, ...   \n",
       "...      ...                                                ...   \n",
       "77504      1  [2, 2210, 8262, 17, 555, 3755, 9, 9, 9, 13, 20...   \n",
       "77505      1  [2, 2593, 11491, 2119, 13, 45, 1569, 255, 38, ...   \n",
       "77506      1  [2, 489, 728, 13, 20248, 489, 728, 448, 5873, ...   \n",
       "77507      1  [2, 90, 1679, 31, 221, 22, 38, 76, 778, 43, 40...   \n",
       "77508      1  [2, 21, 15298, 448, 705, 24, 63, 90, 485, 160,...   \n",
       "\n",
       "                                          token_type_ids  \\\n",
       "0      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1                         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                  ...   \n",
       "77504  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "77505  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "77506  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "77507  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "77508  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                          attention_mask  \n",
       "0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1                         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "2      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "...                                                  ...  \n",
       "77504  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "77505  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "77506  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "77507  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "77508  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "\n",
       "[77509 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(examples):\n",
    "    return tokenizer(examples['message'], truncation=True)\n",
    "\n",
    "train_ds = ds['train'].map(\n",
    "    tokenize, \n",
    "    batched=True,\n",
    "    remove_columns=['message'],\n",
    "    # remove_columns=['title', 'description', 'text'],\n",
    ")\n",
    "eval_ds = ds['validation'].map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    "    remove_columns=['message'],\n",
    "    # remove_columns=['title', 'description', 'text'],\n",
    ")\n",
    "train_ds.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca78a0b",
   "metadata": {},
   "source": [
    "Create the transformer model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36846278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from transformers.models.bert.modeling_bert import BertModel, BertPreTrainedModel\n",
    "\n",
    "# https://github.com/huggingface/transformers/blob/65659a29cf5a079842e61a63d57fa24474288998/src/transformers/models/bert/modeling_bert.py#L1486\n",
    "\n",
    "class BertForSequenceClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            **kwargs,\n",
    "        )\n",
    "        cls_outputs = outputs.last_hidden_state[:, 0, :]\n",
    "        cls_outputs = self.dropout(cls_outputs)\n",
    "        logits = self.classifier(cls_outputs)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b15ac966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at albert-base-v1 and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    transformer_name,\n",
    "    #num_labels=len(labels),\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "model = (\n",
    "    BertForSequenceClassification\n",
    "    .from_pretrained(transformer_name, config=config).to(device)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae1a93c",
   "metadata": {},
   "source": [
    "Create the trainer object and train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d805f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "num_epochs = 2\n",
    "batch_size = 48\n",
    "weight_decay = 0.01\n",
    "model_name = f'{transformer_name}-sequence-classification'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name,\n",
    "    log_level='error',\n",
    "    num_train_epochs=num_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    eval_strategy='epoch',\n",
    "    weight_decay=weight_decay,\n",
    "    fp16=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77a0699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    y_true = eval_pred.label_ids\n",
    "    y_pred = np.argmax(eval_pred.predictions, axis=-1)\n",
    "    return {'accuracy': accuracy_score(y_true, y_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c16ead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    processing_class=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301aefd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1949' max='3230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1949/3230 48:44 < 32:03, 0.67 it/s, Epoch 1.21/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.274900</td>\n",
       "      <td>0.233149</td>\n",
       "      <td>0.894932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13f080c4-b891-456b-a818-4567356ae5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"league_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1ec029",
   "metadata": {},
   "source": [
    "Evaluate on the test partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa4b892f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00013cd810843e3bdba523e3debc64f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8809 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 1060, 2094, 6151, 4241, 20377, 2102, 903...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 18792, 24330, 2243, 2004, 1045, 5454, 38...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 23755, 24403, 2232, 2377, 1012, 1012, 10...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 2644, 8457, 2327, 1012, 999, 1024, 2644,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 9152, 2094, 9152, 2094, 2097, 3046, 8954...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8804</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 3926, 102]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8805</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 2025, 1054, 2135, 2524, 1034, 1034, 1024...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8806</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 17710, 12096, 15630, 14841, 3501, 14141,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8807</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 3189, 10905, 2571, 10047, 2081, 2005, 20...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8808</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 1046, 1005, 9932, 17852, 7634, 2063, 339...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8809 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                          input_ids  \\\n",
       "0         1  [101, 1060, 2094, 6151, 4241, 20377, 2102, 903...   \n",
       "1         1  [101, 18792, 24330, 2243, 2004, 1045, 5454, 38...   \n",
       "2         0  [101, 23755, 24403, 2232, 2377, 1012, 1012, 10...   \n",
       "3         0  [101, 2644, 8457, 2327, 1012, 999, 1024, 2644,...   \n",
       "4         1  [101, 9152, 2094, 9152, 2094, 2097, 3046, 8954...   \n",
       "...     ...                                                ...   \n",
       "8804      0                                   [101, 3926, 102]   \n",
       "8805      0  [101, 2025, 1054, 2135, 2524, 1034, 1034, 1024...   \n",
       "8806      1  [101, 17710, 12096, 15630, 14841, 3501, 14141,...   \n",
       "8807      1  [101, 3189, 10905, 2571, 10047, 2081, 2005, 20...   \n",
       "8808      0  [101, 1046, 1005, 9932, 17852, 7634, 2063, 339...   \n",
       "\n",
       "                                         token_type_ids  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "8804                                          [0, 0, 0]   \n",
       "8805  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "8806  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "8807  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "8808  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                         attention_mask  \n",
       "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "...                                                 ...  \n",
       "8804                                          [1, 1, 1]  \n",
       "8805  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "8806  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "8807  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "8808  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "\n",
       "[8809 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds = ds['test'].map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    "    remove_columns=['message'],\n",
    "    # remove_columns=['title', 'description', 'text'],\n",
    ")\n",
    "test_ds.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fe018fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-4.546875 ,  5.2109375],\n",
       "       [-3.3828125,  4.015625 ],\n",
       "       [ 4.8632812, -5.46875  ],\n",
       "       ...,\n",
       "       [-5.0351562,  5.859375 ],\n",
       "       [-2.0351562,  2.3496094],\n",
       "       [ 4.5703125, -5.1484375]], dtype=float32), label_ids=array([1, 1, 0, ..., 1, 1, 0]), metrics={'test_loss': 0.1072918027639389, 'test_accuracy': 0.9617436712453173, 'test_runtime': 78.4789, 'test_samples_per_second': 112.247, 'test_steps_per_second': 2.345})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = trainer.predict(test_ds)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14221494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not toxic       0.96      0.95      0.96      3821\n",
      "       toxic       0.96      0.97      0.97      4988\n",
      "\n",
      "    accuracy                           0.96      8809\n",
      "   macro avg       0.96      0.96      0.96      8809\n",
      "weighted avg       0.96      0.96      0.96      8809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = output.label_ids\n",
    "y_pred = np.argmax(output.predictions, axis=-1)\n",
    "target_names = [\"not toxic\", \"toxic\"]\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e08a12ea-cab4-44da-bec2-ed4528e11c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5961d65ea09541f38b2cecfd28a46a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                    input_ids         token_type_ids  \\\n",
      "0      0                            [101, 11350, 102]              [0, 0, 0]   \n",
      "1      0          [101, 2023, 2003, 1037, 11350, 102]     [0, 0, 0, 0, 0, 0]   \n",
      "2      0                 [101, 1999, 1996, 3075, 102]        [0, 0, 0, 0, 0]   \n",
      "3      1  [101, 2388, 11263, 23177, 2053, 16429, 102]  [0, 0, 0, 0, 0, 0, 0]   \n",
      "\n",
      "          attention_mask  \n",
      "0              [1, 1, 1]  \n",
      "1     [1, 1, 1, 1, 1, 1]  \n",
      "2        [1, 1, 1, 1, 1]  \n",
      "3  [1, 1, 1, 1, 1, 1, 1]  \n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 3.9316406, -4.1953125],\n",
      "       [-3.9746094,  4.765625 ],\n",
      "       [-2.7597656,  3.1152344],\n",
      "       [-3.6992188,  4.2890625]], dtype=float32), label_ids=array([0, 0, 0, 1]), metrics={'test_loss': 3.6554322242736816, 'test_accuracy': 0.5, 'test_runtime': 0.0222, 'test_samples_per_second': 179.776, 'test_steps_per_second': 44.944})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3.9316406, -4.1953125],\n",
       "       [-3.9746094,  4.765625 ],\n",
       "       [-2.7597656,  3.1152344],\n",
       "       [-3.6992188,  4.2890625]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample DataFrame (make sure your real DataFrame has the correct structure)\n",
    "test_df = {\"message\": [\"hi\"], \"label\": [0]}\n",
    "\n",
    "cols = [\"message\", \"label\"]\n",
    "data = [[\"soup\",0],[\"this is a soup\", 0],[\"in the library\", 0],[\"Motherfucking noob\",1]]\n",
    "test = pd.DataFrame(data, columns = cols)\n",
    "\n",
    "# Convert the DataFrame to a Dataset\n",
    "test_dataset = Dataset.from_pandas(test)\n",
    "#test_dataset.reset_index(inplace=True, drop=True)\n",
    "\n",
    "dota_ds=DatasetDict()\n",
    "dota_ds['test'] = Dataset.from_pandas(test)\n",
    "#dota_ds.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "# Now, map the tokenization function to the dataset\n",
    "# Since your key for the dataset is 'test', make sure you access 'test' from dota_ds\n",
    "test_ds_dota = dota_ds['test'].map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    "    remove_columns=['message'],  # Removing 'message' column after tokenization\n",
    ")\n",
    "\n",
    "# Convert to pandas DataFrame (for inspection)\n",
    "test_ds_dota_df = test_ds_dota.to_pandas()\n",
    "\n",
    "# Output the tokenized dataset\n",
    "print(test_ds_dota_df)\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "output_dota = trainer.predict(test_ds_dota)\n",
    "\n",
    "# Print or inspect the output\n",
    "print(output_dota)\n",
    "\n",
    "output_dota.predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6b20006b-15e7-46ae-8166-9fad7ba8c5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(output_dota.predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "64f432b9-1f2b-4eee-ad78-2eb489fd32a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COMMEND ME TY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sorry nex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is the best soup?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>man that silence on axe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not coming into play</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>wt?f?asfU JGOFIDLK,YH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>you must really suck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>YOU HAVE IDIOT PLAYER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>SUPER IDIOT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>fuck off weab</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3267 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      message  label\n",
       "0               COMMEND ME TY      0\n",
       "1                   sorry nex      0\n",
       "2      what is the best soup?      0\n",
       "3     man that silence on axe      0\n",
       "4        not coming into play      0\n",
       "...                       ...    ...\n",
       "3262    wt?f?asfU JGOFIDLK,YH      1\n",
       "3263     you must really suck      1\n",
       "3264    YOU HAVE IDIOT PLAYER      1\n",
       "3265              SUPER IDIOT      1\n",
       "3266            fuck off weab      1\n",
       "\n",
       "[3267 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = open('classes.txt').read().splitlines()\n",
    "df = pd.read_csv(\"tagged-data.csv\", header=0)\n",
    "# Get only the text and label columns\n",
    "df = df[[\"text\",\"target\"]]\n",
    "print(labels)\n",
    "df = df.rename(columns={\"text\": \"message\"})\n",
    "df = df.rename(columns={\"target\": \"label\"})\n",
    "\n",
    "df['label'] = df['label'].replace(2,1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c162d352-e4bb-4fa8-8863-9bb291fe3735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['message', 'label'],\n",
       "        num_rows: 3267\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dota_ds = DatasetDict()\n",
    "dota_ds['test'] = Dataset.from_pandas(df)\n",
    "dota_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bb3a0296-4ac3-4753-95bf-1811569d0200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa56fb51e584793868e13caaa3e2ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3267 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 4012, 3549, 2094, 2033, 5939, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 3374, 11265, 2595, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 2054, 2003, 1996, 2190, 11350, 1029, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 2158, 2008, 4223, 2006, 12946, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 2025, 2746, 2046, 2377, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 1059, 2102, 1029, 1042, 1029, 2004, 1126...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 2017, 2442, 2428, 11891, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 2017, 2031, 10041, 2447, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 3565, 10041, 102]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 6616, 2125, 2057, 7875, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3267 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                          input_ids  \\\n",
       "0         0           [101, 4012, 3549, 2094, 2033, 5939, 102]   \n",
       "1         0                      [101, 3374, 11265, 2595, 102]   \n",
       "2         0    [101, 2054, 2003, 1996, 2190, 11350, 1029, 102]   \n",
       "3         0          [101, 2158, 2008, 4223, 2006, 12946, 102]   \n",
       "4         0                 [101, 2025, 2746, 2046, 2377, 102]   \n",
       "...     ...                                                ...   \n",
       "3262      1  [101, 1059, 2102, 1029, 1042, 1029, 2004, 1126...   \n",
       "3263      1                [101, 2017, 2442, 2428, 11891, 102]   \n",
       "3264      1                [101, 2017, 2031, 10041, 2447, 102]   \n",
       "3265      1                            [101, 3565, 10041, 102]   \n",
       "3266      1                 [101, 6616, 2125, 2057, 7875, 102]   \n",
       "\n",
       "                                         token_type_ids  \\\n",
       "0                                 [0, 0, 0, 0, 0, 0, 0]   \n",
       "1                                       [0, 0, 0, 0, 0]   \n",
       "2                              [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "3                                 [0, 0, 0, 0, 0, 0, 0]   \n",
       "4                                    [0, 0, 0, 0, 0, 0]   \n",
       "...                                                 ...   \n",
       "3262  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3263                                 [0, 0, 0, 0, 0, 0]   \n",
       "3264                                 [0, 0, 0, 0, 0, 0]   \n",
       "3265                                       [0, 0, 0, 0]   \n",
       "3266                                 [0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                         attention_mask  \n",
       "0                                 [1, 1, 1, 1, 1, 1, 1]  \n",
       "1                                       [1, 1, 1, 1, 1]  \n",
       "2                              [1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "3                                 [1, 1, 1, 1, 1, 1, 1]  \n",
       "4                                    [1, 1, 1, 1, 1, 1]  \n",
       "...                                                 ...  \n",
       "3262  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3263                                 [1, 1, 1, 1, 1, 1]  \n",
       "3264                                 [1, 1, 1, 1, 1, 1]  \n",
       "3265                                       [1, 1, 1, 1]  \n",
       "3266                                 [1, 1, 1, 1, 1, 1]  \n",
       "\n",
       "[3267 rows x 4 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds_dota = dota_ds['test'].map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    "    remove_columns=['message'],\n",
    "    # remove_columns=['title', 'description', 'text'],\n",
    ")\n",
    "test_ds_dota.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dbdfc968-7bd0-4e8e-80dc-eeb375bfc764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-1.2646484,  1.6171875],\n",
       "       [ 4.3359375, -4.8046875],\n",
       "       [-4.1445312,  4.9257812],\n",
       "       ...,\n",
       "       [-4.1601562,  5.0390625],\n",
       "       [ 2.6445312, -2.53125  ],\n",
       "       [-3.5527344,  4.3085938]], dtype=float32), label_ids=array([0, 0, 0, ..., 1, 1, 1]), metrics={'test_loss': 2.7994821071624756, 'test_accuracy': 0.5677992041628406, 'test_runtime': 1.7236, 'test_samples_per_second': 1895.454, 'test_steps_per_second': 40.033})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dota = trainer.predict(test_ds_dota)\n",
    "output_dota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "31b5b3a5-d1d9-4a4b-a784-62a80e8af23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dota.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e3ee660f-9e9f-4a57-9076-05b75b7c06bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(output_dota.predictions, axis=-1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "381d9fd2-b3f1-4ede-8114-c1690f846512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not toxic       0.63      0.53      0.57      1800\n",
      "       toxic       0.52      0.62      0.56      1467\n",
      "\n",
      "    accuracy                           0.57      3267\n",
      "   macro avg       0.57      0.57      0.57      3267\n",
      "weighted avg       0.58      0.57      0.57      3267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = output_dota.label_ids\n",
    "y_pred = np.argmax(output_dota.predictions, axis=-1)\n",
    "target_names = [\"not toxic\", \"toxic\"]\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57eb5d5-717f-4bca-af11-8e3ac2020403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faed948a-aefd-4fec-b611-d12075a7aae0",
   "metadata": {},
   "source": [
    "## Testing for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aec60862-e991-4145-b88e-27c01a9840f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import Trainer\n",
    "from transformers import AutoConfig\n",
    "from torch import nn\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from transformers.models.bert.modeling_bert import BertModel, BertPreTrainedModel\n",
    "\n",
    "# https://github.com/huggingface/transformers/blob/65659a29cf5a079842e61a63d57fa24474288998/src/transformers/models/bert/modeling_bert.py#L1486\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "transformer_name = \"league_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(transformer_name, use_fast=True)\n",
    "\n",
    "def tokenize(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding='max_length')\n",
    "\n",
    "\n",
    "class BertForSequenceClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            **kwargs,\n",
    "        )\n",
    "        cls_outputs = outputs.last_hidden_state[:, 0, :]\n",
    "        cls_outputs = self.dropout(cls_outputs)\n",
    "        logits = self.classifier(cls_outputs)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"league_model\",\n",
    "    #num_labels=len(labels),\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "model = (\n",
    "    BertForSequenceClassification\n",
    "    .from_pretrained(\"league_model\", config=config)\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11282330-5700-4b72-9035-8c5e26611042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d85005438d36489597a2be47a213ab38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>soup</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this is a soup</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in the library</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motherfucking noob</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AHAHHHAHHASDHADHU</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bread and butter</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soup is bad</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I hope you beat your children</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>die soup</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I hope you die</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I hope your kids die</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I hope your kids</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I hope your kids soup</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>die udyr</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>die kids</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I hope your lose</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I hope your succeed</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0\n",
       "soup                           0\n",
       "this is a soup                 1\n",
       "in the library                 1\n",
       "Motherfucking noob             1\n",
       "AHAHHHAHHASDHADHU              0\n",
       "bread and butter               1\n",
       "soup is bad                    1\n",
       "I hope you beat your children  1\n",
       "die soup                       0\n",
       "I hope you die                 0\n",
       "I hope your kids die           0\n",
       "I hope your kids               0\n",
       "I hope your kids soup          0\n",
       "die udyr                       0\n",
       "die kids                       0\n",
       "I hope your lose               1\n",
       "I hope your succeed            0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"text\", \"label\"]\n",
    "data = [[\"soup\",0],\n",
    "        [\"this is a soup\", 0],\n",
    "        [\"in the library\", 0],\n",
    "        [\"Motherfucking noob\",1],\n",
    "        [\"AHAHHHAHHASDHADHU\",0],\n",
    "        [\"bread and butter\",0],\n",
    "        [\"soup is bad\",0],\n",
    "        [\"I hope you beat your children\",1],\n",
    "        [\"die soup\",0], \n",
    "        [\"I hope you die\",1],\n",
    "        [\"I hope your kids die\",1],\n",
    "        [\"I hope your kids\", 0],\n",
    "        [\"I hope your kids soup\", 0],\n",
    "        [\"die udyr\", 1],\n",
    "        [\"die kids\", 1],\n",
    "        [\"I hope your lose\",0],\n",
    "        [\"I hope your succeed\",0],\n",
    "       ]\n",
    "test = pd.DataFrame(data, columns = cols)\n",
    "\n",
    "# Convert the DataFrame to a Dataset\n",
    "test_dataset = Dataset.from_pandas(test)\n",
    "#test_dataset.reset_index(inplace=True, drop=True)\n",
    "\n",
    "dota_ds=DatasetDict()\n",
    "dota_ds['test'] = Dataset.from_pandas(test)\n",
    "#dota_ds.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "# Now, map the tokenization function to the dataset\n",
    "# Since your key for the dataset is 'test', make sure you access 'test' from dota_ds\n",
    "test_ds_dota = dota_ds['test'].map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    "    # remove_columns=['message'],  # Removing 'message' column after tokenization\n",
    ")\n",
    "\n",
    "# Convert to pandas DataFrame (for inspection)\n",
    "test_ds_dota_df = test_ds_dota.to_pandas()\n",
    "\n",
    "# Output the tokenized dataset\n",
    "# print(test_ds_dota_df)\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "output_dota = trainer.predict(test_ds_dota)\n",
    "\n",
    "# Print or inspect the output\n",
    "# print(output_dota)\n",
    "\n",
    "output_dota.predictions\n",
    "\n",
    "chats = test_dataset[\"text\"]\n",
    "labels = np.argmax(output_dota.predictions, axis=-1)\n",
    "pd.DataFrame(labels, chats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b26547c4-9f34-4217-8a3b-64d918fa536b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac9b266-f038-443c-8b44-733bba12fa9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
