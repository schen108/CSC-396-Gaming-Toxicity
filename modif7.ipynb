{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97919e77-6a5d-4cc4-81ee-22accfdd58c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "random seed: 1234\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# enable tqdm in pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# set to True to use the gpu (if there is one available)\n",
    "use_gpu = True\n",
    "\n",
    "# select device\n",
    "device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')\n",
    "print(f'device: {device.type}')\n",
    "\n",
    "# random seed\n",
    "seed = 1234\n",
    "\n",
    "# set random seed\n",
    "if seed is not None:\n",
    "    print(f'random seed: {seed}')\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "083f3fa2-03d4-4d10-9559-09b7bc9934e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_league_data(filename):\n",
    "    # read csv file\n",
    "    df = pd.read_csv(filename, header=0)\n",
    "    # Get only the text and label columns\n",
    "    return df[[\"message\",\"toxicity_label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54ef1048-b08a-46af-9fa4-f17f5c79124b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>report for unskilled player is useless thx &lt;3 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mimimi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im comming for you riven pfft focus Zed always...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thx top no flash for what ? he has 2 kill in l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IIII ISI K udyr top dnt us see it? CAMP MORE P...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88083</th>\n",
       "      <td>gj &amp;gt;&amp;lt; xD i said ss gj stop go alone plz ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88084</th>\n",
       "      <td>i like the new un-do button GET BACK GET BACK ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88085</th>\n",
       "      <td>thx now i can b its ok re top sry thought cait...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88086</th>\n",
       "      <td>take t brb swian i was ogin b i was going blue...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88087</th>\n",
       "      <td>much farm lulu at top? ty need blue push op i ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88088 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 message  label\n",
       "0      report for unskilled player is useless thx <3 ...      0\n",
       "1                                                 mimimi      0\n",
       "2      im comming for you riven pfft focus Zed always...      1\n",
       "3      thx top no flash for what ? he has 2 kill in l...      1\n",
       "4      IIII ISI K udyr top dnt us see it? CAMP MORE P...      0\n",
       "...                                                  ...    ...\n",
       "88083  gj &gt;&lt; xD i said ss gj stop go alone plz ...      1\n",
       "88084  i like the new un-do button GET BACK GET BACK ...      1\n",
       "88085  thx now i can b its ok re top sry thought cait...      0\n",
       "88086  take t brb swian i was ogin b i was going blue...      1\n",
       "88087  much farm lulu at top? ty need blue push op i ...      0\n",
       "\n",
       "[88088 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = open('classes.txt').read().splitlines()\n",
    "data = read_league_data('dataToxic.csv')\n",
    "print(labels)\n",
    "data = data.rename(columns={\"toxicity_label\": \"label\"})\n",
    "data['message'] = data['message'].str.replace(',',' ',regex=False)\n",
    "data['label'] = data['label'].apply(lambda x: 1 if x == 'toxic' else 0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bd371c8-84f9-496d-9079-101a225acfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rows: 70,470\n",
      "eval rows: 8,809\n",
      "test rows: 8,809\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, eval_and_test_df = train_test_split(data, train_size=0.8, random_state\n",
    "= 4)\n",
    "eval_df, test_df = train_test_split(eval_and_test_df, train_size=0.5, random_state = 4)\n",
    "train_df.reset_index(inplace=True, drop=True)\n",
    "eval_df.reset_index(inplace=True, drop=True)\n",
    "test_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(f'train rows: {len(train_df.index):,}')\n",
    "print(f'eval rows: {len(eval_df.index):,}')\n",
    "print(f'test rows: {len(test_df.index):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e755738-249f-4620-9ccb-0e955bda15fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i looked at the game too late thoughzed no its...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>can i have next blue? ty amumu uselesss 3 time...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-.-\" blizt too report</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>help bluw blue heimer noob fizz you dont help ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes lee is in bot no mana</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8804</th>\n",
       "      <td>... so bad tf tf are u fucking retarded? go mi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8805</th>\n",
       "      <td>nvm can u pls ward or do smth u arnt doing any...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8806</th>\n",
       "      <td>ss re i tank GG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8807</th>\n",
       "      <td>yes nice ward wow jinx att speed wat ? gj send...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8808</th>\n",
       "      <td>need blue heca repor´t report nunu please i af...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8809 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                message  label\n",
       "0     i looked at the game too late thoughzed no its...      1\n",
       "1     can i have next blue? ty amumu uselesss 3 time...      0\n",
       "2                                 -.-\" blizt too report      1\n",
       "3     help bluw blue heimer noob fizz you dont help ...      1\n",
       "4                             yes lee is in bot no mana      0\n",
       "...                                                 ...    ...\n",
       "8804  ... so bad tf tf are u fucking retarded? go mi...      1\n",
       "8805  nvm can u pls ward or do smth u arnt doing any...      1\n",
       "8806                                    ss re i tank GG      0\n",
       "8807  yes nice ward wow jinx att speed wat ? gj send...      1\n",
       "8808  need blue heca repor´t report nunu please i af...      1\n",
       "\n",
       "[8809 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94aa26c8-e7be-4359-b01d-3f1d956ac6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['message', 'label'],\n",
       "        num_rows: 70470\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['message', 'label'],\n",
       "        num_rows: 8809\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['message', 'label'],\n",
       "        num_rows: 8809\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "ds = DatasetDict()\n",
    "ds['train'] = Dataset.from_pandas(train_df)\n",
    "ds['validation'] = Dataset.from_pandas(eval_df)\n",
    "ds['test'] = Dataset.from_pandas(test_df)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1566aa31-f211-426b-8990-c4da43852843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "transformer_name = 'bert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(transformer_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa8fe29d-4113-4c56-aeac-d0220f11f51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 70470/70470 [00:04<00:00, 16706.98 examples/s]\n",
      "Map: 100%|██████████| 8809/8809 [00:00<00:00, 13621.64 examples/s]\n",
      "Map: 100%|██████████| 8809/8809 [00:00<00:00, 18818.79 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(examples):\n",
    "    return tokenizer(examples['message'], truncation=True)\n",
    "\n",
    "train_ds = ds['train'].map(tokenize, batched=True, remove_columns=['message'])\n",
    "eval_ds = ds['validation'].map(tokenize, batched=True, remove_columns=['message'])\n",
    "test_ds = ds['test'].map(tokenize, batched=True, remove_columns=['message'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b65b7410-e72e-4a3e-937e-f88ed84e86ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertPreTrainedModel\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "class BertLSTMForSequenceClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        # BERT Model\n",
    "        self.bert = BertModel(config)\n",
    "        # LSTM Layer (works with BERT hidden size)\n",
    "        self.lstm = nn.LSTM(input_size=config.hidden_size, hidden_size=128, num_layers=1, batch_first=True, dropout=0.1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        # Fully connected layer to output logits\n",
    "        self.classifier = nn.Linear(128, config.num_labels)\n",
    "        \n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None):\n",
    "        # Pass through BERT\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        # Get sequence-level output from BERT\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        # Pass through LSTM layer\n",
    "        lstm_output, (hn, cn) = self.lstm(sequence_output)\n",
    "        # Get the last hidden state from LSTM\n",
    "        # pooled_output = hn[-1]  # Using the last hidden state (it could be any strategy: mean, max, etc.)\n",
    "        pooled_output=sequence_output.mean(dim=1)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        # Compute loss if labels are provided\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "        \n",
    "        return SequenceClassifierOutput(loss=loss, logits=logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66fafcf1-eb7c-4427-8da3-f6dad6d682db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "Some weights of BertLSTMForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'lstm.bias_hh_l0', 'lstm.bias_ih_l0', 'lstm.weight_hh_l0', 'lstm.weight_ih_l0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "# Load the configuration\n",
    "config = AutoConfig.from_pretrained(\n",
    "    transformer_name,\n",
    "    num_labels=2  # assuming binary classification (toxic / not toxic)\n",
    ")\n",
    "\n",
    "# Instantiate the hybrid model\n",
    "model = BertLSTMForSequenceClassification.from_pretrained(transformer_name, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "058b4890-f4ba-438a-ac87-287cad5d59ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'{transformer_name}-sequence-classification',\n",
    "    log_level='error',\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=48,\n",
    "    per_device_eval_batch_size=48,\n",
    "    eval_strategy='epoch',\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    disable_tqdm=False\n",
    ")\n",
    "\n",
    "# Compute metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    y_true = eval_pred.label_ids\n",
    "    y_pred = np.argmax(eval_pred.predictions, axis=-1)\n",
    "    return {'accuracy': accuracy_score(y_true, y_pred)}\n",
    "\n",
    "# Create Trainer object\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    # add this\n",
    "    processing_class=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcd3fb7-85e1-42bf-8f39-af7c8f0f3749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2669b6-8aa0-4c56-b2ea-ade56bf5d9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2bbc8e8-fff0-471e-acf0-a4d67016b54a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (48x768 and 128x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/transformers/trainer.py:2164\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2165\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2169\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/transformers/trainer.py:2522\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2516\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2517\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2519\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2520\u001b[0m )\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2522\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2525\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2526\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2528\u001b[0m ):\n\u001b[1;32m   2529\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2530\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/transformers/trainer.py:3655\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3653\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs)\n\u001b[1;32m   3654\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3655\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3657\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3661\u001b[0m ):\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/transformers/trainer.py:3709\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3707\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3708\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[0;32m-> 3709\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3710\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3711\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/accelerate/utils/operations.py:823\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/accelerate/utils/operations.py:811\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 811\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/torch/amp/autocast_mode.py:44\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 27\u001b[0m, in \u001b[0;36mBertLSTMForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, labels)\u001b[0m\n\u001b[1;32m     25\u001b[0m pooled_output\u001b[38;5;241m=\u001b[39msequence_output\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     26\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n\u001b[0;32m---> 27\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpooled_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Compute loss if labels are provided\u001b[39;00m\n\u001b[1;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (48x768 and 128x2)"
     ]
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4749c809-424d-482b-ab2d-7e53e86666fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = trainer.predict(test_ds)\n",
    "\n",
    "y_true = output.label_ids\n",
    "y_pred = np.argmax(output.predictions, axis=-1)\n",
    "target_names = [\"not toxic\", \"toxic\"]\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d1ed7b-21d6-473a-8d6c-fd0fc6b4db06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20b20a0-7cb8-49dc-a875-e39053b57b2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test\n",
    "# Sample DataFrame (make sure your real DataFrame has the correct structure)\n",
    "test_df = {\"message\": [\"hi\"], \"label\": [0]}\n",
    "\n",
    "cols = [\"message\", \"label\"]\n",
    "data = [[\"soup\",0],[\"this is a soup\", 0],[\"in the library\", 0],[\"Motherfucking noob\",1], [\"you guys were winning early game\", 0], [\"Support my ass senpai\", 1], [\"ur fucking ass at this game go kys\",1]]\n",
    "test = pd.DataFrame(data, columns = cols)\n",
    "\n",
    "# Convert the DataFrame to a Dataset\n",
    "test_dataset = Dataset.from_pandas(test)\n",
    "#test_dataset.reset_index(inplace=True, drop=True)\n",
    "\n",
    "dota_ds=DatasetDict()\n",
    "dota_ds['test'] = Dataset.from_pandas(test)\n",
    "#dota_ds.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "# Now, map the tokenization function to the dataset\n",
    "# Since your key for the dataset is 'test', make sure you access 'test' from dota_ds\n",
    "test_ds_dota = dota_ds['test'].map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    "    remove_columns=['message'],  # Removing 'message' column after tokenization\n",
    ")\n",
    "\n",
    "# Convert to pandas DataFrame (for inspection)\n",
    "test_ds_dota_df = test_ds_dota.to_pandas()\n",
    "\n",
    "# Output the tokenized dataset\n",
    "print(test_ds_dota_df)\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "output_dota = trainer.predict(test_ds_dota)\n",
    "\n",
    "# Print or inspect the output\n",
    "print(output_dota)\n",
    "\n",
    "output_dota.predictions\n",
    "\n",
    "np.argmax(output_dota.predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74de27bd-1ad6-47ff-9866-0df2beb806a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.save_model(\"second trial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8318cc5-6955-47cb-ab3b-1ff25ecd7f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049eeef6-a5dc-458a-8b74-78c803445f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fad7e0-8a5b-4b81-8c46-55688a6603ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e4374-1068-4933-aba0-bb4b2b1d4786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec731e1e-1159-4954-bf22-13707da92758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1040ffd-ad2e-4644-9bf7-753a329dec46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae464fa-e0b1-4d05-adec-492fa3d013eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df={\"message\": [\"hi\"], \"label\":[0]}\n",
    "\n",
    "ds['test2'] = Dataset.from_pandas(test_df)\n",
    "test_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "ds = DatasetDict()\n",
    "ds['test2'] = Dataset.from_pandas(test_df)\n",
    "\n",
    "\n",
    "dota_ds = DatasetDict()\n",
    "dota_ds['test'] = Dataset.from_pandas(df)\n",
    "dota_ds\n",
    "\n",
    "test_ds_dota = dota_ds['test2'].map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    "    remove_columns=['message'],\n",
    "    # remove_columns=['title', 'description', 'text'],\n",
    ")\n",
    "test_ds_dota.to_pandas()\n",
    "\n",
    "\n",
    "output_dota = trainer.predict(test_ds_dota)\n",
    "output_dota\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e04fb5-3fca-4547-9cae-eabce251d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import Trainer\n",
    "\n",
    "# Sample DataFrame (make sure your real DataFrame has the correct structure)\n",
    "test_df = {\"message\": [\"hi\"], \"label\": [0]}\n",
    "\n",
    "# Convert the DataFrame to a Dataset\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "test_dataset.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Initialize DatasetDict\n",
    "ds = DatasetDict()\n",
    "ds['test2'] = test_dataset\n",
    "\n",
    "# If you're working with a second dataset for Dota:\n",
    "# Create another example dataset for \"dota\"\n",
    "dota_df = {\"message\": [\"hello\", \"good game\"], \"label\": [0, 1]}  # Example\n",
    "dota_ds = DatasetDict()\n",
    "dota_ds['test'] = Dataset.from_pandas(dota_df)\n",
    "\n",
    "\n",
    "# Now, map the tokenization function to the dataset\n",
    "# Since your key for the dataset is 'test', make sure you access 'test' from dota_ds\n",
    "test_ds_dota = dota_ds['test'].map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    "    remove_columns=['message'],  # Removing 'message' column after tokenization\n",
    ")\n",
    "\n",
    "# Convert to pandas DataFrame (for inspection)\n",
    "test_ds_dota_df = test_ds_dota.to_pandas()\n",
    "\n",
    "# Output the tokenized dataset\n",
    "print(test_ds_dota_df)\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "output_dota = trainer.predict(test_ds_dota)\n",
    "\n",
    "# Print or inspect the output\n",
    "# print(output_dota)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f027fb9d-5c4f-4a68-83d8-750147e2272e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaf744e-4d41-4788-824a-01bfd1d2a96e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60e3f02-654b-4826-adf9-329b256ff68a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e04a1ad-39b4-48c4-9dcf-d48b04eda2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5ad024-a999-4b5b-99ba-de889a304583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a210e9-8381-4c0c-8e89-bbed7f26d569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b22f1f2-e053-4386-9858-4bb296a6d1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabdb8f3-efa8-4fae-a02d-56b0dce38bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75888034-c1bd-4c25-a09b-387460f66c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2dac4b90-ead4-4df6-ac11-09c355f37c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COMMEND ME TY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sorry nex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is the best soup?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>man that silence on axe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not coming into play</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>wt?f?asfU JGOFIDLK,YH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>you must really suck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>YOU HAVE IDIOT PLAYER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>SUPER IDIOT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>fuck off weab</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3267 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      message  target\n",
       "0               COMMEND ME TY       0\n",
       "1                   sorry nex       0\n",
       "2      what is the best soup?       0\n",
       "3     man that silence on axe       0\n",
       "4        not coming into play       0\n",
       "...                       ...     ...\n",
       "3262    wt?f?asfU JGOFIDLK,YH       1\n",
       "3263     you must really suck       1\n",
       "3264    YOU HAVE IDIOT PLAYER       1\n",
       "3265              SUPER IDIOT       1\n",
       "3266            fuck off weab       1\n",
       "\n",
       "[3267 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = open('classes.txt').read().splitlines()\n",
    "df = pd.read_csv(\"tagged-data.csv\", header=0)\n",
    "# Get only the text and label columns\n",
    "df = df[[\"text\",\"target\"]]\n",
    "print(labels)\n",
    "df = df.rename(columns={\"text\": \"message\"})\n",
    "df['target'] = df['target'].replace(2,1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72320b73-9fd0-4c72-91e0-8e5b24831118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['message', 'target'],\n",
       "        num_rows: 3267\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dota_ds = DatasetDict()\n",
    "dota_ds['test'] = Dataset.from_pandas(df)\n",
    "dota_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93b0a39f-264c-4431-8a1b-dfc9d0008e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3267/3267 [00:00<00:00, 44944.13 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 18732, 25290, 11680, 2137, 22157, 157, 3...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 2959, 24928, 1775, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 1184, 1110, 1103, 1436, 13128, 136, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 1299, 1115, 3747, 1113, 16301, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 1136, 1909, 1154, 1505, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 192, 1204, 136, 175, 136, 1112, 2087, 25...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 1128, 1538, 1541, 13054, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 19141, 145, 26390, 2036, 10999, 19368, 1...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 156, 18124, 9637, 10999, 19368, 1942, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 9367, 1228, 1195, 6639, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3267 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target                                          input_ids  \\\n",
       "0          0  [101, 18732, 25290, 11680, 2137, 22157, 157, 3...   \n",
       "1          0                      [101, 2959, 24928, 1775, 102]   \n",
       "2          0     [101, 1184, 1110, 1103, 1436, 13128, 136, 102]   \n",
       "3          0          [101, 1299, 1115, 3747, 1113, 16301, 102]   \n",
       "4          0                 [101, 1136, 1909, 1154, 1505, 102]   \n",
       "...      ...                                                ...   \n",
       "3262       1  [101, 192, 1204, 136, 175, 136, 1112, 2087, 25...   \n",
       "3263       1                [101, 1128, 1538, 1541, 13054, 102]   \n",
       "3264       1  [101, 19141, 145, 26390, 2036, 10999, 19368, 1...   \n",
       "3265       1   [101, 156, 18124, 9637, 10999, 19368, 1942, 102]   \n",
       "3266       1                 [101, 9367, 1228, 1195, 6639, 102]   \n",
       "\n",
       "                                         token_type_ids  \\\n",
       "0                           [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1                                       [0, 0, 0, 0, 0]   \n",
       "2                              [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "3                                 [0, 0, 0, 0, 0, 0, 0]   \n",
       "4                                    [0, 0, 0, 0, 0, 0]   \n",
       "...                                                 ...   \n",
       "3262  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3263                                 [0, 0, 0, 0, 0, 0]   \n",
       "3264            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "3265                           [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "3266                                 [0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                         attention_mask  \n",
       "0                           [1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "1                                       [1, 1, 1, 1, 1]  \n",
       "2                              [1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "3                                 [1, 1, 1, 1, 1, 1, 1]  \n",
       "4                                    [1, 1, 1, 1, 1, 1]  \n",
       "...                                                 ...  \n",
       "3262  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3263                                 [1, 1, 1, 1, 1, 1]  \n",
       "3264            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "3265                           [1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "3266                                 [1, 1, 1, 1, 1, 1]  \n",
       "\n",
       "[3267 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds_dota = dota_ds['test'].map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    "    remove_columns=['message'],\n",
    "    # remove_columns=['title', 'description', 'text'],\n",
    ")\n",
    "test_ds_dota.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1456d038-ddd4-45e6-9f18-d53a016ce5d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (48x768 and 128x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output_dota \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_ds_dota\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m output_dota\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/transformers/trainer.py:4129\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4126\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   4128\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 4129\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\n\u001b[1;32m   4131\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4132\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   4133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/transformers/trainer.py:4245\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4242\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[1;32m   4244\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[0;32m-> 4245\u001b[0m losses, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4246\u001b[0m main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4247\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   4248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4249\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/transformers/trainer.py:4471\u001b[0m, in \u001b[0;36mTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   4469\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4470\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 4471\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m   4473\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ignore_keys)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/accelerate/utils/operations.py:823\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/accelerate/utils/operations.py:811\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 811\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/torch/amp/autocast_mode.py:44\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 27\u001b[0m, in \u001b[0;36mBertLSTMForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, labels)\u001b[0m\n\u001b[1;32m     25\u001b[0m pooled_output\u001b[38;5;241m=\u001b[39msequence_output\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     26\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n\u001b[0;32m---> 27\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpooled_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Compute loss if labels are provided\u001b[39;00m\n\u001b[1;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-gpu/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (48x768 and 128x2)"
     ]
    }
   ],
   "source": [
    "output_dota = trainer.predict(test_ds_dota)\n",
    "output_dota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a41f5c3-8672-468f-b34f-5e78fe6ef333",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(output_dota.predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1f4973-d00d-4142-8430-0305035f282c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce7027a-96d7-41cf-97b3-c2f04dc74e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true = output_dota.label_ids\n",
    "y_pred = np.argmax(output_dota.predictions, axis=-1)\n",
    "target_names = [\"not toxic\", \"toxic\"]\n",
    "# print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8d6ec1-ef9e-4079-b996-76eaa0e109f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76c04b5-9817-410d-8e47-6903f1b0bac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee25cbe-4f35-4204-95f4-93ebdae4edee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7fdbbec-bfa3-4610-97cc-937b11bde05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained(\"./first trial/\", torch_dtype=torch.float16, attn_implementation=\"sdpa\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e85e78d-22d4-4d59-89ca-954da1a0182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    # add this\n",
    "    processing_class=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb5ea2d9-31bd-4ada-a976-64579bc6cd23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=(array([[[ 3.5660338e-01,  1.1932389e-01,  3.5519615e-01, ...,\n",
       "         -1.9240448e-01,  3.7812015e-01, -3.9147049e-01],\n",
       "        [ 2.2477226e-01,  6.9438174e-02, -2.5595695e-01, ...,\n",
       "          3.9837021e-01,  6.2837720e-01,  1.2285419e-01],\n",
       "        [-2.3931769e-01,  1.0512624e-01, -2.1768065e-02, ...,\n",
       "          7.7340508e-01, -1.7562312e-01, -2.0802525e-01],\n",
       "        ...,\n",
       "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
       "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
       "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
       "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02]],\n",
       "\n",
       "       [[ 5.5914807e-01,  2.9495448e-02,  1.6484490e-01, ...,\n",
       "          1.8535736e-01,  2.5782201e-01, -1.4750110e-01],\n",
       "        [ 6.7941672e-01, -4.5113319e-01,  1.9211547e-01, ...,\n",
       "          4.4155937e-01,  5.7889801e-01,  3.9043745e-01],\n",
       "        [ 8.3845395e-01, -5.2060544e-01,  1.6793384e-01, ...,\n",
       "          2.4469656e-01, -2.9097931e-02, -9.8840229e-02],\n",
       "        ...,\n",
       "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
       "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
       "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
       "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02]],\n",
       "\n",
       "       [[ 5.3479296e-01, -1.2748561e-02,  8.8244915e-02, ...,\n",
       "         -5.3357027e-02,  1.5357450e-01, -5.2322552e-02],\n",
       "        [ 7.0788932e-01, -6.4579976e-01,  5.2853251e-01, ...,\n",
       "         -4.3265766e-01, -2.1770933e-01,  4.6887100e-02],\n",
       "        [ 2.4048746e-01,  1.6614258e-01,  1.0136425e-01, ...,\n",
       "         -9.0556648e-03, -2.4827810e-01,  2.5577471e-01],\n",
       "        ...,\n",
       "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
       "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
       "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
       "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 2.9686898e-01,  3.4265670e-01,  1.2428525e-03, ...,\n",
       "         -1.9375756e-01,  5.4608917e-01, -2.5707558e-02],\n",
       "        [ 4.9431361e-02,  2.1112888e-01,  3.2374895e-01, ...,\n",
       "          5.2949297e-01,  6.2774909e-01,  3.1193590e-01],\n",
       "        [-9.3774962e-01,  7.4904215e-01, -5.9708808e-02, ...,\n",
       "          9.9511981e-01,  8.5971224e-01, -2.2882134e-01],\n",
       "        ...,\n",
       "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
       "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
       "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
       "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02]],\n",
       "\n",
       "       [[ 6.6144958e-02,  1.3764277e-01,  1.5292586e-01, ...,\n",
       "         -7.7686623e-02,  4.1807112e-01,  1.3190441e-01],\n",
       "        [-2.4003034e-02, -6.7598082e-02,  1.4073339e-01, ...,\n",
       "          8.0302876e-01,  2.9529464e-01,  4.5028526e-01],\n",
       "        [ 4.3458078e-02,  3.5272092e-01,  1.0778608e-01, ...,\n",
       "          7.4905157e-01, -3.9428192e-01,  4.9798042e-01],\n",
       "        ...,\n",
       "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
       "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
       "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
       "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02]],\n",
       "\n",
       "       [[ 5.5202526e-01,  3.6217412e-01,  1.1914991e-01, ...,\n",
       "          4.3086216e-02,  1.8403029e-01, -1.6607350e-01],\n",
       "        [ 5.6302059e-01, -4.3290439e-01,  5.1310188e-01, ...,\n",
       "         -3.1713185e-01,  3.3290219e-01,  5.5252407e-02],\n",
       "        [ 1.8575563e-01,  6.1389375e-01,  4.7579959e-02, ...,\n",
       "         -1.1896370e-02,  4.7953650e-02,  3.0538794e-01],\n",
       "        ...,\n",
       "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
       "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
       "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
       "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02]]], dtype=float32), array([[-0.5776367 ,  0.38623047,  0.9995117 , ...,  1.        ,\n",
       "        -0.9321289 ,  0.9921875 ],\n",
       "       [-0.7060547 ,  0.4819336 ,  1.        , ...,  1.        ,\n",
       "        -0.57714844,  0.98828125],\n",
       "       [-0.61035156,  0.4633789 ,  0.9995117 , ...,  1.        ,\n",
       "        -0.9350586 ,  0.9868164 ],\n",
       "       ...,\n",
       "       [-0.6533203 ,  0.53125   ,  1.        , ...,  1.        ,\n",
       "        -0.9291992 ,  0.99658203],\n",
       "       [-0.6875    ,  0.4609375 ,  1.        , ...,  1.        ,\n",
       "        -0.78222656,  0.99609375],\n",
       "       [-0.68310547,  0.5058594 ,  1.        , ...,  1.        ,\n",
       "        -0.86083984,  0.9946289 ]], dtype=float32)), label_ids=None, metrics={'test_model_preparation_time': 0.0038, 'test_runtime': 2.0922, 'test_samples_per_second': 1561.551, 'test_steps_per_second': 32.98})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dota = trainer.predict(test_ds_dota)\n",
    "output_dota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcb54998-5873-41ec-bc0c-64a6d94f5f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dota.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4f5be2-8d88-4846-96d2-66c4ba7825b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
