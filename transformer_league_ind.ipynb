{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56c031b5",
   "metadata": {},
   "source": [
    "# League (Individual) Transformer Model (BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42020eb",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40bd59e",
   "metadata": {},
   "source": [
    "Some initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133ffdc9-f28b-46fa-84ee-19ded042aaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install datasets\n",
    "!pip3 install transformers\n",
    "!pip install -U accelerate\n",
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3afe3bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "random seed: 1234\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# enable tqdm in pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# set to True to use the gpu (if there is one available)\n",
    "use_gpu = True\n",
    "\n",
    "# select device\n",
    "device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')\n",
    "print(f'device: {device.type}')\n",
    "\n",
    "# random seed\n",
    "seed = 1234\n",
    "\n",
    "# set random seed\n",
    "if seed is not None:\n",
    "    print(f'random seed: {seed}')\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009a5afc",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3441f3",
   "metadata": {},
   "source": [
    "Read the train/dev/test datasets and create a HuggingFace `Dataset` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1885c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_league_data(filename):\n",
    "    # read csv file\n",
    "    df = pd.read_csv(filename, header=0)\n",
    "    # Get only the text and label columns\n",
    "    return df[[\"message\",\"toxicity_label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03f51a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['0','1']\n",
    "data = read_league_data('chatupdate.csv')\n",
    "print(labels)\n",
    "data = data.rename(columns={\"toxicity_label\": \"label\"})\n",
    "data['label'] = data['label'].apply(lambda x: 1 if x == 'toxic' else 0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7518aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, eval_and_test_df = train_test_split(data, train_size=0.8, random_state\n",
    "= 4)\n",
    "eval_df, test_df = train_test_split(eval_and_test_df, train_size=0.5, random_state = 4)\n",
    "train_df.reset_index(inplace=True, drop=True)\n",
    "eval_df.reset_index(inplace=True, drop=True)\n",
    "test_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(f'train rows: {len(train_df.index):,}')\n",
    "print(f'eval rows: {len(eval_df.index):,}')\n",
    "print(f'test rows: {len(test_df.index):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3c727f-1bef-45b8-a179-f4b3bcd974c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06f040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "ds = DatasetDict()\n",
    "ds['train'] = Dataset.from_pandas(train_df)\n",
    "ds['validation'] = Dataset.from_pandas(eval_df)\n",
    "ds['test'] = Dataset.from_pandas(test_df)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1426f0",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac23185a",
   "metadata": {},
   "source": [
    "Tokenize the texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65e8d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "transformer_name = 'bert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(transformer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a2caf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(examples):\n",
    "    return tokenizer(examples['message'], truncation=True)\n",
    "\n",
    "train_ds = ds['train'].map(\n",
    "    tokenize, \n",
    "    batched=True,\n",
    "    remove_columns=['message'],\n",
    "    # remove_columns=['title', 'description', 'text'],\n",
    ")\n",
    "eval_ds = ds['validation'].map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    "    remove_columns=['message'],\n",
    "    # remove_columns=['title', 'description', 'text'],\n",
    ")\n",
    "train_ds.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3629a767",
   "metadata": {},
   "source": [
    "## Model Creation and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca78a0b",
   "metadata": {},
   "source": [
    "Create the transformer model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36846278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from transformers.models.bert.modeling_bert import BertModel, BertPreTrainedModel\n",
    "\n",
    "# https://github.com/huggingface/transformers/blob/65659a29cf5a079842e61a63d57fa24474288998/src/transformers/models/bert/modeling_bert.py#L1486\n",
    "\n",
    "class BertForSequenceClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            **kwargs,\n",
    "        )\n",
    "        cls_outputs = outputs.last_hidden_state[:, 0, :]\n",
    "        cls_outputs = self.dropout(cls_outputs)\n",
    "        logits = self.classifier(cls_outputs)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15ac966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    transformer_name,\n",
    "    #num_labels=len(labels),\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "model = (\n",
    "    BertForSequenceClassification\n",
    "    .from_pretrained(transformer_name, config=config)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae1a93c",
   "metadata": {},
   "source": [
    "Create the trainer object and train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d805f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "num_epochs = 2\n",
    "batch_size = 24\n",
    "weight_decay = 0.01\n",
    "model_name = f'{transformer_name}-sequence-classification'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name,\n",
    "    log_level='error',\n",
    "    num_train_epochs=num_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    eval_strategy='epoch',\n",
    "    weight_decay=weight_decay,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77a0699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    y_true = eval_pred.label_ids\n",
    "    y_pred = np.argmax(eval_pred.predictions, axis=-1)\n",
    "    return {'accuracy': accuracy_score(y_true, y_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c16ead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    processing_class=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301aefd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284cfe7d",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a581446f",
   "metadata": {},
   "source": [
    "### Testing on League Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4b892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = ds['test'].map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    "    remove_columns=['message'],\n",
    "    # remove_columns=['title', 'description', 'text'],\n",
    ")\n",
    "test_ds.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe018fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = trainer.predict(test_ds)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14221494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = output.label_ids\n",
    "y_pred = np.argmax(output.predictions, axis=-1)\n",
    "target_names = [\"not toxic\", \"toxic\"]\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a291ac",
   "metadata": {},
   "source": [
    "## Testing on Dota Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f432b9-1f2b-4eee-ad78-2eb489fd32a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = open('classes.txt').read().splitlines()\n",
    "df = pd.read_csv(\"tagged-data.csv\", header=0)\n",
    "# Get only the text and label columns\n",
    "df = df[[\"text\",\"target\"]]\n",
    "print(labels)\n",
    "df = df.rename(columns={\"text\": \"message\"})\n",
    "df = df.rename(columns={\"target\": \"label\"})\n",
    "\n",
    "df['label'] = df['label'].replace(2,1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c162d352-e4bb-4fa8-8863-9bb291fe3735",
   "metadata": {},
   "outputs": [],
   "source": [
    "dota_ds = DatasetDict()\n",
    "dota_ds['test'] = Dataset.from_pandas(df)\n",
    "dota_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3a0296-4ac3-4753-95bf-1811569d0200",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds_dota = dota_ds['test'].map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    "    remove_columns=['message'],\n",
    "    # remove_columns=['title', 'description', 'text'],\n",
    ")\n",
    "test_ds_dota.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdfc968-7bd0-4e8e-80dc-eeb375bfc764",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dota = trainer.predict(test_ds_dota)\n",
    "output_dota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d9fd2-b3f1-4ede-8114-c1690f846512",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = output_dota.label_ids\n",
    "y_pred = np.argmax(output_dota.predictions, axis=-1)\n",
    "target_names = [\"not toxic\", \"toxic\"]\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03870c6c-4497-41ac-8535-6582b16b7b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66195f6-ce42-4f65-af70-bedf341d68df",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e2d29fac-2e83-4544-b594-087abd14dd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.array(['very interesting hero,man that silence on axe'])\n",
    "test_df = pd.DataFrame(test_data,columns=['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c096e67-5774-4ecb-85ba-f001a2a0ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ds = DatasetDict()\n",
    "input_ds['test'] = Dataset.from_pandas(test_df)\n",
    "input_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977fec0a-c4c5-4cdf-a500-520dac742f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds_input = input_ds['test'].map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    "    remove_columns=['message'],\n",
    "    # remove_columns=['title', 'description', 'text'],\n",
    ")\n",
    "test_ds_input.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9392226-91a1-4731-8ea1-b281ee7b18ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_input = trainer.predict(test_ds_input)\n",
    "output_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90418904-3aaf-4a12-a05a-b6227dd97f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_input.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750b1107-527b-4b0f-8386-feb09db095a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(output_input.predictions, axis=-1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce10557-460b-4689-b224-ccf36b3e072e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd47e64-6b71-49fa-a92c-a9b1e43433a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
